{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import config  # edit config.py as needed\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import scipy as sp\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from lifelines import KaplanMeierFitter\n",
    "from metric import score  # edit metric.py as needed\n",
    "from scipy.stats import rankdata\n",
    "from seed import seed_everything  # edit seed.py as needed\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    DYR_RUN = False\n",
    "    EXP_NAME = config.EXP_NAME\n",
    "    AUTHOR = config.KAGGLE_USERNAME\n",
    "    COMPETITION = config.KAGGLE_COMPETITION_NAME\n",
    "    DATA_PATH = config.COMP_DATASET_DIR\n",
    "    OUTPUT_DIR = config.OUTPUT_DIR\n",
    "    MODEL_PATH = config.OUTPUT_DIR / \"models\"\n",
    "    METHOD_LIST = [\"lightgbm\", \"xgboost\", \"catboost\"]\n",
    "    SEED = 42\n",
    "    n_folds = 2 if DYR_RUN else 10\n",
    "    target_col_list = [\"y\"]\n",
    "    # group_col = \"race_group\"  # Required for GroupKFold (edit as needed)\n",
    "    # stratified_col = \"race_group\"  # Required for StratifiedKFold (edit as needed)\n",
    "    stratified_cols = [\"efs\", \"race_group\"]  # Required for MultilabelStratifiedKFold（edit as needed）\n",
    "    num_boost_round = 100 if DYR_RUN else 1000000\n",
    "    early_stopping_round = 10 if DYR_RUN else 100\n",
    "    verbose = 500\n",
    "\n",
    "    # https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "    regression_lgb_params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"mae\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        # \"num_leaves\": 31,\n",
    "        \"max_depth\": 3,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"seed\": SEED,\n",
    "        \"device\": \"cuda\",  # cpu/gpu/cuda\n",
    "    }\n",
    "    # https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "    regression_xgb_params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"mae\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"max_depth\": 3,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"enable_categorical\": True,\n",
    "        \"min_child_weight\": 80,\n",
    "        \"random_state\": SEED,\n",
    "        \"device\": \"cuda\",  # cpu/gpu/cuda\n",
    "    }\n",
    "    # https://catboost.ai/docs/en/references/training-parameters/\n",
    "    regression_cat_params = {\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"iterations\": num_boost_round,\n",
    "        # \"depth\": 7,\n",
    "        \"grow_policy\": \"Lossguide\",\n",
    "        \"random_seed\": SEED,\n",
    "        \"task_type\": \"GPU\",  # CPU/GPU\n",
    "    }\n",
    "\n",
    "    model_weight_dict = {\"lightgbm\": 0.40, \"xgboost\": 0.30, \"catboost\": 0.30}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "seed_everything(CFG.SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "train = pl.read_csv(CFG.DATA_PATH / \"train.csv\", try_parse_dates=True)\n",
    "test = pl.read_csv(CFG.DATA_PATH / \"test.csv\", try_parse_dates=True)\n",
    "# make index column\n",
    "# train = train.with_row_index()\n",
    "# test = test.with_row_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Preprocess(ここに前処理や特徴量エンジニアリングを記述)\n",
    "# ====================================================\n",
    "def transform_survival_probability(df, time_col=\"efs_time\", event_col=\"efs\"):\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df[time_col], df[event_col])\n",
    "    y = kmf.survival_function_at_times(df[time_col]).values\n",
    "    return y\n",
    "\n",
    "\n",
    "# def preprocess(df: pl.DataFrame) -> pl.DataFrame:\n",
    "#     output = df.clone()\n",
    "#     return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = preprocess(train)\n",
    "# test = preprocess(test)\n",
    "\n",
    "# apply Kaplan-Meier\n",
    "# TODO: もっと適切な目的変数があるかも（人種で層別化してモデル作るとか？）\n",
    "y = transform_survival_probability(train, time_col=\"efs_time\", event_col=\"efs\")\n",
    "train = train.with_columns(pl.Series(y).alias(\"y\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Make fold column\n",
    "# ====================================================\n",
    "fold_array = np.zeros(len(train))\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.SEED)\n",
    "# for i, (_, val_idx) in enumerate(skf.split(train, train[CFG.stratified_col])):\n",
    "#     fold = i + 1\n",
    "#     fold_array[val_idx] = fold\n",
    "# train = train.with_columns(pl.Series(fold_array, dtype=pl.Int8).alias(\"fold\"))\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.SEED)\n",
    "for i, (_, test_index) in enumerate(mskf.split(train, train[CFG.stratified_cols])):\n",
    "    fold = i + 1\n",
    "    fold_array[test_index] = fold\n",
    "train = train.with_columns(pl.Series(fold_array, dtype=pl.Int8).alias(\"fold\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.to_pandas()\n",
    "test = test.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'hla_match_c_high', 'hla_high_res_8', 'tbi_status', 'arrhythmia', 'hla_low_res_6', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'hla_high_res_6', 'cmv_status', 'hla_high_res_10', 'hla_match_dqb1_high', 'tce_imm_match', 'hla_nmdp_6', 'hla_match_c_low', 'rituximab', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'year_hct', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hla_match_a_high', 'hepatic_severe', 'donor_age', 'prior_tumor', 'hla_match_b_low', 'peptic_ulcer', 'age_at_hct', 'hla_match_a_low', 'gvhd_proph', 'rheum_issue', 'sex_match', 'hla_match_b_high', 'race_group', 'comorbidity_score', 'karnofsky_score', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'hla_low_res_8', 'cardiac', 'hla_match_drb1_high', 'pulm_moderate', 'hla_low_res_10']\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Set categorical columns etc. (pandas operation from here)\n",
    "# ====================================================\n",
    "RMV = [\"ID\", \"efs\", \"efs_time\", \"y\", \"fold\"]\n",
    "FEATURES = [c for c in train.columns if c not in RMV]\n",
    "print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In these features, there are 35 CATEGORICAL FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status', 'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe', 'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match', 'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'cardiac', 'pulm_moderate']\n"
     ]
    }
   ],
   "source": [
    "CATS = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype == \"object\":\n",
    "        CATS.append(c)\n",
    "        train[c] = train[c].fillna(\"NAN\")\n",
    "        test[c] = test[c].fillna(\"NAN\")\n",
    "print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We LABEL ENCODE the CATEGORICAL FEATURES: dri_score, psych_disturb, cyto_score, diabetes, tbi_status, arrhythmia, graft_type, vent_hist, renal_issue, pulm_severe, prim_disease_hct, cmv_status, tce_imm_match, rituximab, prod_type, cyto_score_detail, conditioning_intensity, ethnicity, obesity, mrd_hct, in_vivo_tcd, tce_match, hepatic_severe, prior_tumor, peptic_ulcer, gvhd_proph, rheum_issue, sex_match, race_group, hepatic_mild, tce_div_match, donor_related, melphalan_dose, cardiac, pulm_moderate, "
     ]
    }
   ],
   "source": [
    "combined = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "# print(\"Combined data shape:\", combined.shape )\n",
    "\n",
    "# LABEL ENCODE CATEGORICAL FEATURES\n",
    "print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \", end=\"\")\n",
    "for c in FEATURES:\n",
    "    # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "    if c in CATS:\n",
    "        print(f\"{c}, \", end=\"\")\n",
    "        combined[c], _ = combined[c].factorize()\n",
    "        combined[c] -= combined[c].min()\n",
    "        combined[c] = combined[c].astype(\"int32\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "\n",
    "    # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "    else:\n",
    "        if combined[c].dtype == \"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype == \"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "\n",
    "train = combined.iloc[: len(train)].copy()\n",
    "test = combined.iloc[len(train) :].reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Training functions\n",
    "# ====================================================\n",
    "def lightgbm_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "        params=CFG.regression_lgb_params,\n",
    "        train_set=lgb_train,\n",
    "        num_boost_round=CFG.num_boost_round,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=CFG.early_stopping_round, verbose=CFG.verbose),\n",
    "            lgb.log_evaluation(CFG.verbose),\n",
    "        ],\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def xgboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "):\n",
    "    xgb_train = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
    "    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
    "    model = xgb.train(\n",
    "        CFG.regression_xgb_params,\n",
    "        dtrain=xgb_train,\n",
    "        num_boost_round=CFG.num_boost_round,\n",
    "        evals=[(xgb_train, \"train\"), (xgb_valid, \"eval\")],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose_eval=CFG.verbose,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid, enable_categorical=True))\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def catboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostRegressor(**CFG.regression_cat_params)\n",
    "    model.fit(\n",
    "        cat_train,\n",
    "        eval_set=[cat_valid],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose=CFG.verbose,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def gradient_boosting_model_cv_training(\n",
    "    method: str, train_df: pd.DataFrame, features: list, categorical_features: list\n",
    "):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions_df = pd.DataFrame(np.zeros((len(train_df), len(CFG.target_col_list))), columns=[\"prediction\"])\n",
    "    for target_col in CFG.target_col_list:\n",
    "        oof_predictions = np.zeros(len(train_df))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"{method} training fold {fold+1} {target_col}\")\n",
    "            x_train = train_df[train_df[\"fold\"] != fold + 1][features]\n",
    "            y_train = train_df[train_df[\"fold\"] != fold + 1][target_col]\n",
    "            x_valid = train_df[train_df[\"fold\"] == fold + 1][features]\n",
    "            y_valid = train_df[train_df[\"fold\"] == fold + 1][target_col]\n",
    "            if method == \"lightgbm\":\n",
    "                model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            if method == \"xgboost\":\n",
    "                model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid)\n",
    "            if method == \"catboost\":\n",
    "                model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "\n",
    "            # Save best model\n",
    "            save_model_path = (\n",
    "                CFG.MODEL_PATH / f\"{method}_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\"\n",
    "            )\n",
    "            save_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            pickle.dump(\n",
    "                model,\n",
    "                open(\n",
    "                    save_model_path,\n",
    "                    \"wb\",\n",
    "                ),\n",
    "            )\n",
    "            # Add to out of folds array\n",
    "            oof_predictions[train_df[\"fold\"] == fold + 1] = valid_pred\n",
    "            del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "            gc.collect()\n",
    "        # oof_predictions_df[target_col] = oof_predictions\n",
    "\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_predictions_df[\"ID\"] = train_df[\"ID\"].values\n",
    "    oof_predictions_df[\"prediction\"] = oof_predictions\n",
    "    oof_predictions_df.to_csv(CFG.OUTPUT_DIR / f\"oof_{method}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\", index=False)\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    y_true = train_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
    "    m = score(y_true.copy(), oof_predictions_df.copy(), \"ID\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{method} our out of folds CV score is {m}\")\n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 1 y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.605867\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.129599\tvalid_1's l1: 0.134534\n",
      "[1000]\ttraining's l1: 0.124948\tvalid_1's l1: 0.132145\n",
      "[1500]\ttraining's l1: 0.121644\tvalid_1's l1: 0.13105\n",
      "[2000]\ttraining's l1: 0.118869\tvalid_1's l1: 0.130347\n",
      "[2500]\ttraining's l1: 0.11644\tvalid_1's l1: 0.129804\n",
      "[3000]\ttraining's l1: 0.114214\tvalid_1's l1: 0.129471\n",
      "[3500]\ttraining's l1: 0.112243\tvalid_1's l1: 0.129265\n",
      "[4000]\ttraining's l1: 0.110396\tvalid_1's l1: 0.129016\n",
      "Early stopping, best iteration is:\n",
      "[4309]\ttraining's l1: 0.109289\tvalid_1's l1: 0.128916\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 2 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606309\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.129689\tvalid_1's l1: 0.132719\n",
      "[1000]\ttraining's l1: 0.124903\tvalid_1's l1: 0.130298\n",
      "[1500]\ttraining's l1: 0.121618\tvalid_1's l1: 0.129194\n",
      "[2000]\ttraining's l1: 0.118923\tvalid_1's l1: 0.128551\n",
      "[2500]\ttraining's l1: 0.116556\tvalid_1's l1: 0.128127\n",
      "[3000]\ttraining's l1: 0.114399\tvalid_1's l1: 0.127964\n",
      "[3500]\ttraining's l1: 0.112393\tvalid_1's l1: 0.127827\n",
      "[4000]\ttraining's l1: 0.110508\tvalid_1's l1: 0.127703\n",
      "[4500]\ttraining's l1: 0.108738\tvalid_1's l1: 0.127524\n",
      "Early stopping, best iteration is:\n",
      "[4610]\ttraining's l1: 0.108342\tvalid_1's l1: 0.127514\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 3 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606178\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.129928\tvalid_1's l1: 0.131335\n",
      "[1000]\ttraining's l1: 0.125086\tvalid_1's l1: 0.128974\n",
      "[1500]\ttraining's l1: 0.121867\tvalid_1's l1: 0.127784\n",
      "[2000]\ttraining's l1: 0.119238\tvalid_1's l1: 0.127074\n",
      "[2500]\ttraining's l1: 0.116959\tvalid_1's l1: 0.12669\n",
      "[3000]\ttraining's l1: 0.114837\tvalid_1's l1: 0.126299\n",
      "[3500]\ttraining's l1: 0.112851\tvalid_1's l1: 0.125982\n",
      "[4000]\ttraining's l1: 0.111006\tvalid_1's l1: 0.125816\n",
      "[4500]\ttraining's l1: 0.109261\tvalid_1's l1: 0.125662\n",
      "Early stopping, best iteration is:\n",
      "[4506]\ttraining's l1: 0.109239\tvalid_1's l1: 0.125658\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 4 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606172\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.129974\tvalid_1's l1: 0.131442\n",
      "[1000]\ttraining's l1: 0.125251\tvalid_1's l1: 0.129063\n",
      "[1500]\ttraining's l1: 0.121968\tvalid_1's l1: 0.127987\n",
      "[2000]\ttraining's l1: 0.119267\tvalid_1's l1: 0.127382\n",
      "[2500]\ttraining's l1: 0.116943\tvalid_1's l1: 0.126932\n",
      "[3000]\ttraining's l1: 0.114813\tvalid_1's l1: 0.126514\n",
      "[3500]\ttraining's l1: 0.112833\tvalid_1's l1: 0.126214\n",
      "[4000]\ttraining's l1: 0.110974\tvalid_1's l1: 0.126067\n",
      "Early stopping, best iteration is:\n",
      "[4256]\ttraining's l1: 0.110044\tvalid_1's l1: 0.125989\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 5 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606298\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.129852\tvalid_1's l1: 0.132342\n",
      "[1000]\ttraining's l1: 0.125138\tvalid_1's l1: 0.129977\n",
      "[1500]\ttraining's l1: 0.121914\tvalid_1's l1: 0.128878\n",
      "[2000]\ttraining's l1: 0.119227\tvalid_1's l1: 0.128221\n",
      "[2500]\ttraining's l1: 0.116792\tvalid_1's l1: 0.127863\n",
      "[3000]\ttraining's l1: 0.114667\tvalid_1's l1: 0.127623\n",
      "[3500]\ttraining's l1: 0.112685\tvalid_1's l1: 0.127294\n",
      "[4000]\ttraining's l1: 0.110846\tvalid_1's l1: 0.12705\n",
      "Early stopping, best iteration is:\n",
      "[4151]\ttraining's l1: 0.110316\tvalid_1's l1: 0.12702\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 6 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.129851\tvalid_1's l1: 0.132309\n",
      "[1000]\ttraining's l1: 0.125181\tvalid_1's l1: 0.129874\n",
      "[1500]\ttraining's l1: 0.121949\tvalid_1's l1: 0.128756\n",
      "[2000]\ttraining's l1: 0.119284\tvalid_1's l1: 0.128008\n",
      "[2500]\ttraining's l1: 0.116927\tvalid_1's l1: 0.127397\n",
      "[3000]\ttraining's l1: 0.114751\tvalid_1's l1: 0.126952\n",
      "[3500]\ttraining's l1: 0.112735\tvalid_1's l1: 0.126646\n",
      "Early stopping, best iteration is:\n",
      "[3781]\ttraining's l1: 0.111655\tvalid_1's l1: 0.126508\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 7 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.129805\tvalid_1's l1: 0.131075\n",
      "[1000]\ttraining's l1: 0.125164\tvalid_1's l1: 0.128739\n",
      "[1500]\ttraining's l1: 0.121844\tvalid_1's l1: 0.127728\n",
      "[2000]\ttraining's l1: 0.119034\tvalid_1's l1: 0.127097\n",
      "[2500]\ttraining's l1: 0.11661\tvalid_1's l1: 0.126521\n",
      "[3000]\ttraining's l1: 0.114416\tvalid_1's l1: 0.126118\n",
      "Early stopping, best iteration is:\n",
      "[3126]\ttraining's l1: 0.113906\tvalid_1's l1: 0.12602\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 8 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.605996\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.129801\tvalid_1's l1: 0.133756\n",
      "[1000]\ttraining's l1: 0.125007\tvalid_1's l1: 0.131599\n",
      "[1500]\ttraining's l1: 0.121678\tvalid_1's l1: 0.130563\n",
      "[2000]\ttraining's l1: 0.118991\tvalid_1's l1: 0.129884\n",
      "[2500]\ttraining's l1: 0.116616\tvalid_1's l1: 0.129432\n",
      "[3000]\ttraining's l1: 0.114489\tvalid_1's l1: 0.129084\n",
      "Early stopping, best iteration is:\n",
      "[3307]\ttraining's l1: 0.113257\tvalid_1's l1: 0.128867\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 9 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606037\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.129314\tvalid_1's l1: 0.134517\n",
      "[1000]\ttraining's l1: 0.124444\tvalid_1's l1: 0.132241\n",
      "[1500]\ttraining's l1: 0.121145\tvalid_1's l1: 0.131335\n",
      "[2000]\ttraining's l1: 0.118464\tvalid_1's l1: 0.130798\n",
      "[2500]\ttraining's l1: 0.116092\tvalid_1's l1: 0.130378\n",
      "[3000]\ttraining's l1: 0.113895\tvalid_1's l1: 0.13008\n",
      "[3500]\ttraining's l1: 0.111907\tvalid_1's l1: 0.129822\n",
      "[4000]\ttraining's l1: 0.110054\tvalid_1's l1: 0.129726\n",
      "Early stopping, best iteration is:\n",
      "[4323]\ttraining's l1: 0.108929\tvalid_1's l1: 0.129629\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 10 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606450\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.130057\tvalid_1's l1: 0.130498\n",
      "[1000]\ttraining's l1: 0.125366\tvalid_1's l1: 0.128121\n",
      "[1500]\ttraining's l1: 0.122122\tvalid_1's l1: 0.126951\n",
      "[2000]\ttraining's l1: 0.119428\tvalid_1's l1: 0.126128\n",
      "[2500]\ttraining's l1: 0.117076\tvalid_1's l1: 0.125535\n",
      "[3000]\ttraining's l1: 0.114932\tvalid_1's l1: 0.125268\n",
      "[3500]\ttraining's l1: 0.112942\tvalid_1's l1: 0.125048\n",
      "[4000]\ttraining's l1: 0.11105\tvalid_1's l1: 0.124818\n",
      "[4500]\ttraining's l1: 0.109292\tvalid_1's l1: 0.124608\n",
      "[5000]\ttraining's l1: 0.107612\tvalid_1's l1: 0.124448\n",
      "Early stopping, best iteration is:\n",
      "[4951]\ttraining's l1: 0.107765\tvalid_1's l1: 0.12443\n",
      "==================================================\n",
      "lightgbm our out of folds CV score is 0.669733543211472\n",
      "==================================================\n",
      "--------------------------------------------------\n",
      "xgboost training fold 1 y\n",
      "[0]\ttrain-mae:0.15480\teval-mae:0.15672\n",
      "[500]\ttrain-mae:0.13144\teval-mae:0.13476\n",
      "[1000]\ttrain-mae:0.12714\teval-mae:0.13193\n",
      "[1500]\ttrain-mae:0.12456\teval-mae:0.13064\n",
      "[2000]\ttrain-mae:0.12245\teval-mae:0.12989\n",
      "[2500]\ttrain-mae:0.12072\teval-mae:0.12950\n",
      "[3000]\ttrain-mae:0.11925\teval-mae:0.12932\n",
      "[3099]\ttrain-mae:0.11900\teval-mae:0.12932\n",
      "--------------------------------------------------\n",
      "xgboost training fold 2 y\n",
      "[0]\ttrain-mae:0.15513\teval-mae:0.15468\n",
      "[500]\ttrain-mae:0.13164\teval-mae:0.13327\n",
      "[1000]\ttrain-mae:0.12734\teval-mae:0.13020\n",
      "[1500]\ttrain-mae:0.12463\teval-mae:0.12884\n",
      "[2000]\ttrain-mae:0.12260\teval-mae:0.12820\n",
      "[2500]\ttrain-mae:0.12082\teval-mae:0.12775\n",
      "[3000]\ttrain-mae:0.11935\teval-mae:0.12751\n",
      "[3246]\ttrain-mae:0.11867\teval-mae:0.12749\n",
      "--------------------------------------------------\n",
      "xgboost training fold 3 y\n",
      "[0]\ttrain-mae:0.15503\teval-mae:0.15534\n",
      "[500]\ttrain-mae:0.13187\teval-mae:0.13201\n",
      "[1000]\ttrain-mae:0.12757\teval-mae:0.12917\n",
      "[1500]\ttrain-mae:0.12487\teval-mae:0.12783\n",
      "[2000]\ttrain-mae:0.12282\teval-mae:0.12716\n",
      "[2500]\ttrain-mae:0.12114\teval-mae:0.12676\n",
      "[3000]\ttrain-mae:0.11967\teval-mae:0.12644\n",
      "[3500]\ttrain-mae:0.11828\teval-mae:0.12626\n",
      "[3577]\ttrain-mae:0.11814\teval-mae:0.12630\n",
      "--------------------------------------------------\n",
      "xgboost training fold 4 y\n",
      "[0]\ttrain-mae:0.15511\teval-mae:0.15464\n",
      "[500]\ttrain-mae:0.13186\teval-mae:0.13185\n",
      "[1000]\ttrain-mae:0.12756\teval-mae:0.12898\n",
      "[1500]\ttrain-mae:0.12489\teval-mae:0.12754\n",
      "[2000]\ttrain-mae:0.12287\teval-mae:0.12687\n",
      "[2500]\ttrain-mae:0.12111\teval-mae:0.12632\n",
      "[3000]\ttrain-mae:0.11964\teval-mae:0.12600\n",
      "[3475]\ttrain-mae:0.11831\teval-mae:0.12583\n",
      "--------------------------------------------------\n",
      "xgboost training fold 5 y\n",
      "[0]\ttrain-mae:0.15513\teval-mae:0.15475\n",
      "[500]\ttrain-mae:0.13176\teval-mae:0.13285\n",
      "[1000]\ttrain-mae:0.12730\teval-mae:0.13002\n",
      "[1500]\ttrain-mae:0.12475\teval-mae:0.12877\n",
      "[2000]\ttrain-mae:0.12272\teval-mae:0.12795\n",
      "[2500]\ttrain-mae:0.12102\teval-mae:0.12745\n",
      "[3000]\ttrain-mae:0.11952\teval-mae:0.12717\n",
      "[3159]\ttrain-mae:0.11911\teval-mae:0.12717\n",
      "--------------------------------------------------\n",
      "xgboost training fold 6 y\n",
      "[0]\ttrain-mae:0.15523\teval-mae:0.15409\n",
      "[500]\ttrain-mae:0.13176\teval-mae:0.13303\n",
      "[1000]\ttrain-mae:0.12750\teval-mae:0.12976\n",
      "[1500]\ttrain-mae:0.12481\teval-mae:0.12812\n",
      "[2000]\ttrain-mae:0.12275\teval-mae:0.12719\n",
      "[2500]\ttrain-mae:0.12107\teval-mae:0.12670\n",
      "[2914]\ttrain-mae:0.11980\teval-mae:0.12651\n",
      "--------------------------------------------------\n",
      "xgboost training fold 7 y\n",
      "[0]\ttrain-mae:0.15523\teval-mae:0.15348\n",
      "[500]\ttrain-mae:0.13165\teval-mae:0.13175\n",
      "[1000]\ttrain-mae:0.12731\teval-mae:0.12876\n",
      "[1500]\ttrain-mae:0.12467\teval-mae:0.12732\n",
      "[2000]\ttrain-mae:0.12263\teval-mae:0.12657\n",
      "[2500]\ttrain-mae:0.12091\teval-mae:0.12605\n",
      "[3000]\ttrain-mae:0.11939\teval-mae:0.12578\n",
      "[3500]\ttrain-mae:0.11802\teval-mae:0.12555\n",
      "[4000]\ttrain-mae:0.11678\teval-mae:0.12530\n",
      "[4500]\ttrain-mae:0.11557\teval-mae:0.12522\n",
      "[4677]\ttrain-mae:0.11517\teval-mae:0.12521\n",
      "--------------------------------------------------\n",
      "xgboost training fold 8 y\n",
      "[0]\ttrain-mae:0.15480\teval-mae:0.15700\n",
      "[500]\ttrain-mae:0.13161\teval-mae:0.13399\n",
      "[1000]\ttrain-mae:0.12731\teval-mae:0.13099\n",
      "[1500]\ttrain-mae:0.12468\teval-mae:0.12954\n",
      "[2000]\ttrain-mae:0.12263\teval-mae:0.12874\n",
      "[2500]\ttrain-mae:0.12087\teval-mae:0.12821\n",
      "[3000]\ttrain-mae:0.11937\teval-mae:0.12782\n",
      "[3500]\ttrain-mae:0.11802\teval-mae:0.12763\n",
      "[3737]\ttrain-mae:0.11740\teval-mae:0.12755\n",
      "--------------------------------------------------\n",
      "xgboost training fold 9 y\n",
      "[0]\ttrain-mae:0.15502\teval-mae:0.15511\n",
      "[500]\ttrain-mae:0.13117\teval-mae:0.13460\n",
      "[1000]\ttrain-mae:0.12678\teval-mae:0.13179\n",
      "[1500]\ttrain-mae:0.12415\teval-mae:0.13056\n",
      "[2000]\ttrain-mae:0.12210\teval-mae:0.12976\n",
      "[2500]\ttrain-mae:0.12038\teval-mae:0.12936\n",
      "[2576]\ttrain-mae:0.12018\teval-mae:0.12936\n",
      "--------------------------------------------------\n",
      "xgboost training fold 10 y\n",
      "[0]\ttrain-mae:0.15518\teval-mae:0.15465\n",
      "[500]\ttrain-mae:0.13196\teval-mae:0.13114\n",
      "[1000]\ttrain-mae:0.12770\teval-mae:0.12820\n",
      "[1500]\ttrain-mae:0.12499\teval-mae:0.12675\n",
      "[2000]\ttrain-mae:0.12295\teval-mae:0.12594\n",
      "[2500]\ttrain-mae:0.12121\teval-mae:0.12545\n",
      "[3000]\ttrain-mae:0.11972\teval-mae:0.12514\n",
      "[3500]\ttrain-mae:0.11835\teval-mae:0.12486\n",
      "[4000]\ttrain-mae:0.11711\teval-mae:0.12460\n",
      "[4500]\ttrain-mae:0.11593\teval-mae:0.12442\n",
      "[4752]\ttrain-mae:0.11538\teval-mae:0.12444\n",
      "==================================================\n",
      "xgboost our out of folds CV score is 0.6651083509218473\n",
      "==================================================\n",
      "--------------------------------------------------\n",
      "catboost training fold 1 y\n",
      "0:\tlearn: 0.1760066\ttest: 0.1784437\tbest: 0.1784437 (0)\ttotal: 15.6ms\tremaining: 4h 20m 36s\n",
      "500:\tlearn: 0.1512407\ttest: 0.1596997\tbest: 0.1596997 (500)\ttotal: 5.47s\tremaining: 3h 1m 55s\n",
      "1000:\tlearn: 0.1461753\ttest: 0.1584405\tbest: 0.1584405 (1000)\ttotal: 11.1s\tremaining: 3h 5m 22s\n",
      "1500:\tlearn: 0.1422129\ttest: 0.1579278\tbest: 0.1579106 (1482)\ttotal: 17.4s\tremaining: 3h 13m 23s\n",
      "2000:\tlearn: 0.1388060\ttest: 0.1576335\tbest: 0.1576249 (1988)\ttotal: 23.3s\tremaining: 3h 14m 2s\n",
      "2500:\tlearn: 0.1358319\ttest: 0.1575214\tbest: 0.1574812 (2428)\ttotal: 29.1s\tremaining: 3h 13m 40s\n",
      "bestTest = 0.157481196\n",
      "bestIteration = 2428\n",
      "Shrink model to first 2429 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 2 y\n",
      "0:\tlearn: 0.1762752\ttest: 0.1761540\tbest: 0.1761540 (0)\ttotal: 8.6ms\tremaining: 2h 23m 18s\n",
      "500:\tlearn: 0.1512762\ttest: 0.1589685\tbest: 0.1589685 (500)\ttotal: 4.72s\tremaining: 2h 36m 53s\n",
      "1000:\tlearn: 0.1460572\ttest: 0.1576705\tbest: 0.1576699 (999)\ttotal: 9.99s\tremaining: 2h 46m 10s\n",
      "1500:\tlearn: 0.1420033\ttest: 0.1570954\tbest: 0.1570954 (1500)\ttotal: 15.1s\tremaining: 2h 47m 53s\n",
      "2000:\tlearn: 0.1385959\ttest: 0.1568272\tbest: 0.1568272 (2000)\ttotal: 20s\tremaining: 2h 46m 38s\n",
      "2500:\tlearn: 0.1355793\ttest: 0.1566637\tbest: 0.1566579 (2424)\ttotal: 25.2s\tremaining: 2h 47m 41s\n",
      "bestTest = 0.1566579452\n",
      "bestIteration = 2424\n",
      "Shrink model to first 2425 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 3 y\n",
      "0:\tlearn: 0.1761952\ttest: 0.1768969\tbest: 0.1768969 (0)\ttotal: 14.4ms\tremaining: 4h 39s\n",
      "500:\tlearn: 0.1513970\ttest: 0.1562413\tbest: 0.1562413 (500)\ttotal: 5.12s\tremaining: 2h 50m 16s\n",
      "1000:\tlearn: 0.1461042\ttest: 0.1547114\tbest: 0.1547114 (1000)\ttotal: 10.9s\tremaining: 3h 1m 53s\n",
      "1500:\tlearn: 0.1421574\ttest: 0.1541018\tbest: 0.1540954 (1470)\ttotal: 16.6s\tremaining: 3h 4m 36s\n",
      "2000:\tlearn: 0.1387738\ttest: 0.1537660\tbest: 0.1537633 (1993)\ttotal: 22.5s\tremaining: 3h 6m 46s\n",
      "2500:\tlearn: 0.1357293\ttest: 0.1534943\tbest: 0.1534931 (2493)\ttotal: 27.9s\tremaining: 3h 5m 34s\n",
      "3000:\tlearn: 0.1328657\ttest: 0.1533574\tbest: 0.1533434 (2958)\ttotal: 33.7s\tremaining: 3h 6m 41s\n",
      "bestTest = 0.1533288909\n",
      "bestIteration = 3065\n",
      "Shrink model to first 3066 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 4 y\n",
      "0:\tlearn: 0.1763443\ttest: 0.1756922\tbest: 0.1756922 (0)\ttotal: 10.3ms\tremaining: 2h 52m\n",
      "500:\tlearn: 0.1514926\ttest: 0.1564126\tbest: 0.1564126 (500)\ttotal: 5.06s\tremaining: 2h 48m 19s\n",
      "1000:\tlearn: 0.1463418\ttest: 0.1548816\tbest: 0.1548816 (1000)\ttotal: 11.1s\tremaining: 3h 4m 4s\n",
      "1500:\tlearn: 0.1423534\ttest: 0.1542956\tbest: 0.1542930 (1498)\ttotal: 16.2s\tremaining: 3h 6s\n",
      "2000:\tlearn: 0.1388970\ttest: 0.1539732\tbest: 0.1539631 (1985)\ttotal: 21.7s\tremaining: 3h 3s\n",
      "2500:\tlearn: 0.1357707\ttest: 0.1537378\tbest: 0.1537378 (2500)\ttotal: 27.5s\tremaining: 3h 2m 46s\n",
      "bestTest = 0.1536340569\n",
      "bestIteration = 2716\n",
      "Shrink model to first 2717 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 5 y\n",
      "0:\tlearn: 0.1763239\ttest: 0.1758886\tbest: 0.1758886 (0)\ttotal: 9.96ms\tremaining: 2h 46m 3s\n",
      "500:\tlearn: 0.1515681\ttest: 0.1571378\tbest: 0.1571375 (499)\ttotal: 5.42s\tremaining: 3h 8s\n",
      "1000:\tlearn: 0.1465335\ttest: 0.1562429\tbest: 0.1562365 (995)\ttotal: 11.6s\tremaining: 3h 13m 32s\n",
      "bestTest = 0.1560480975\n",
      "bestIteration = 1332\n",
      "Shrink model to first 1333 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 6 y\n",
      "0:\tlearn: 0.1764000\ttest: 0.1750988\tbest: 0.1750988 (0)\ttotal: 11ms\tremaining: 3h 3m 3s\n",
      "500:\tlearn: 0.1516581\ttest: 0.1567087\tbest: 0.1567087 (500)\ttotal: 5.63s\tremaining: 3h 7m 15s\n",
      "1000:\tlearn: 0.1464713\ttest: 0.1552534\tbest: 0.1552534 (1000)\ttotal: 11s\tremaining: 3h 3m 16s\n",
      "1500:\tlearn: 0.1425415\ttest: 0.1546952\tbest: 0.1546941 (1494)\ttotal: 16.5s\tremaining: 3h 3m 14s\n",
      "2000:\tlearn: 0.1392298\ttest: 0.1543043\tbest: 0.1543034 (1998)\ttotal: 22.1s\tremaining: 3h 4m 7s\n",
      "bestTest = 0.1542922651\n",
      "bestIteration = 2030\n",
      "Shrink model to first 2031 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 7 y\n",
      "0:\tlearn: 0.1763828\ttest: 0.1753545\tbest: 0.1753545 (0)\ttotal: 11.2ms\tremaining: 3h 6m 47s\n",
      "500:\tlearn: 0.1512989\ttest: 0.1573424\tbest: 0.1573424 (500)\ttotal: 5.81s\tremaining: 3h 13m 12s\n",
      "1000:\tlearn: 0.1460170\ttest: 0.1560544\tbest: 0.1560500 (994)\ttotal: 11.3s\tremaining: 3h 8m 41s\n",
      "1500:\tlearn: 0.1421144\ttest: 0.1553938\tbest: 0.1553884 (1494)\ttotal: 17.5s\tremaining: 3h 14m 19s\n",
      "2000:\tlearn: 0.1386315\ttest: 0.1551257\tbest: 0.1551199 (1936)\ttotal: 23.8s\tremaining: 3h 17m 34s\n",
      "2500:\tlearn: 0.1356107\ttest: 0.1549496\tbest: 0.1549496 (2500)\ttotal: 29.9s\tremaining: 3h 18m 55s\n",
      "3000:\tlearn: 0.1327030\ttest: 0.1547737\tbest: 0.1547599 (2969)\ttotal: 36.2s\tremaining: 3h 20m 42s\n",
      "bestTest = 0.1547599186\n",
      "bestIteration = 2969\n",
      "Shrink model to first 2970 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 8 y\n",
      "0:\tlearn: 0.1759853\ttest: 0.1786709\tbest: 0.1786709 (0)\ttotal: 12ms\tremaining: 3h 19m 28s\n",
      "500:\tlearn: 0.1515121\ttest: 0.1590868\tbest: 0.1590866 (498)\ttotal: 5.47s\tremaining: 3h 1m 53s\n",
      "1000:\tlearn: 0.1463250\ttest: 0.1576324\tbest: 0.1576324 (1000)\ttotal: 10.8s\tremaining: 2h 59m 11s\n",
      "1500:\tlearn: 0.1424204\ttest: 0.1569787\tbest: 0.1569787 (1500)\ttotal: 16s\tremaining: 2h 57m 9s\n",
      "2000:\tlearn: 0.1390792\ttest: 0.1566738\tbest: 0.1566663 (1994)\ttotal: 21.4s\tremaining: 2h 57m 49s\n",
      "2500:\tlearn: 0.1361053\ttest: 0.1564934\tbest: 0.1564934 (2500)\ttotal: 26.7s\tremaining: 2h 57m 41s\n",
      "3000:\tlearn: 0.1333621\ttest: 0.1563927\tbest: 0.1563770 (2961)\ttotal: 31.9s\tremaining: 2h 56m 48s\n",
      "bestTest = 0.1563769694\n",
      "bestIteration = 2961\n",
      "Shrink model to first 2962 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 9 y\n",
      "0:\tlearn: 0.1762984\ttest: 0.1760440\tbest: 0.1760440 (0)\ttotal: 12.9ms\tremaining: 3h 34m 42s\n",
      "500:\tlearn: 0.1511807\ttest: 0.1600692\tbest: 0.1600692 (500)\ttotal: 5.16s\tremaining: 2h 51m 36s\n",
      "1000:\tlearn: 0.1458687\ttest: 0.1592216\tbest: 0.1592092 (986)\ttotal: 10.3s\tremaining: 2h 51m 57s\n",
      "1500:\tlearn: 0.1419208\ttest: 0.1588837\tbest: 0.1588769 (1494)\ttotal: 15.5s\tremaining: 2h 52m 20s\n",
      "2000:\tlearn: 0.1385924\ttest: 0.1585962\tbest: 0.1585919 (1999)\ttotal: 20.8s\tremaining: 2h 52m 38s\n",
      "2500:\tlearn: 0.1355544\ttest: 0.1584950\tbest: 0.1584857 (2485)\ttotal: 26.1s\tremaining: 2h 53m 48s\n",
      "bestTest = 0.1583976481\n",
      "bestIteration = 2877\n",
      "Shrink model to first 2878 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 10 y\n",
      "0:\tlearn: 0.1764466\ttest: 0.1746014\tbest: 0.1746014 (0)\ttotal: 8.06ms\tremaining: 2h 14m 25s\n",
      "500:\tlearn: 0.1518367\ttest: 0.1554122\tbest: 0.1554108 (499)\ttotal: 5.22s\tremaining: 2h 53m 27s\n",
      "1000:\tlearn: 0.1466651\ttest: 0.1542733\tbest: 0.1542733 (1000)\ttotal: 10.8s\tremaining: 2h 59m 33s\n",
      "1500:\tlearn: 0.1429154\ttest: 0.1538042\tbest: 0.1538042 (1497)\ttotal: 16.4s\tremaining: 3h 1m 39s\n",
      "2000:\tlearn: 0.1395795\ttest: 0.1534712\tbest: 0.1534645 (1998)\ttotal: 21.7s\tremaining: 3h 25s\n",
      "bestTest = 0.1533806533\n",
      "bestIteration = 2173\n",
      "Shrink model to first 2174 iterations.\n",
      "==================================================\n",
      "catboost our out of folds CV score is 0.6753613199648849\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Training\n",
    "# ====================================================\n",
    "for method in CFG.METHOD_LIST:\n",
    "    gradient_boosting_model_cv_training(method, train, features=FEATURES, categorical_features=CATS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall CV for Ensemble = 0.6738149799017308\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Overall CV\n",
    "# ====================================================\n",
    "oof_lgb = (\n",
    "    pl.read_csv(CFG.OUTPUT_DIR / f\"oof_lightgbm_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\")\n",
    "    .get_column(\"prediction\")\n",
    "    .to_numpy()\n",
    ")\n",
    "oof_xgb = (\n",
    "    pl.read_csv(CFG.OUTPUT_DIR / f\"oof_xgboost_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\")\n",
    "    .get_column(\"prediction\")\n",
    "    .to_numpy()\n",
    ")\n",
    "oof_cat = (\n",
    "    pl.read_csv(CFG.OUTPUT_DIR / f\"oof_catboost_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\")\n",
    "    .get_column(\"prediction\")\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "y_true = train[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = rankdata(oof_xgb) + rankdata(oof_cat) + rankdata(oof_lgb)\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(\"\\nOverall CV for Ensemble =\", m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Inference functions\n",
    "# ====================================================\n",
    "def lightgbm_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"lightgbm_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def xgboost_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"xgboost_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(xgb.DMatrix(x_test, enable_categorical=True))\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def catboost_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"catboost_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list, target_col: str):\n",
    "    x_test = test_df[features]\n",
    "    if method == \"lightgbm\":\n",
    "        test_pred = lightgbm_inference(x_test, target_col)\n",
    "    if method == \"xgboost\":\n",
    "        test_pred = xgboost_inference(x_test, target_col)\n",
    "    if method == \"catboost\":\n",
    "        test_pred = catboost_inference(x_test, target_col)\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "def predicting(input_df: pd.DataFrame, features: list):\n",
    "    output_df = input_df.copy()\n",
    "    for target_col in CFG.target_col_list:\n",
    "        # output_df[target_col] = 0\n",
    "        for method in CFG.METHOD_LIST:\n",
    "            output_df[f\"{method}_pred_{target_col}\"] = gradient_boosting_model_inference(\n",
    "                method, input_df, features, target_col\n",
    "            )\n",
    "            # output_df[target_col] += CFG.model_weight_dict[method] * output_df[f\"{method}_pred_{target_col}\"]\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28801</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28802</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  prediction\n",
       "0  28800         6.0\n",
       "1  28801         9.0\n",
       "2  28802         3.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Inference\n",
    "# ====================================================\n",
    "output_df = predicting(test, FEATURES)\n",
    "pred_lgb = output_df[\"lightgbm_pred_y\"]\n",
    "pred_xgb = output_df[\"xgboost_pred_y\"]\n",
    "pred_cat = output_df[\"catboost_pred_y\"]\n",
    "\n",
    "submission = pd.read_csv(CFG.DATA_PATH / \"sample_submission.csv\")\n",
    "submission[\"prediction\"] = rankdata(pred_lgb) + rankdata(pred_xgb) + rankdata(pred_cat)\n",
    "submission.to_csv(CFG.OUTPUT_DIR / \"submission.csv\", index=False)\n",
    "print(\"Sub shape:\", submission.shape)\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import config  # edit config.py as needed\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import scipy as sp\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from metric import score  # edit metric.py as needed\n",
    "from seed import seed_everything  # edit seed.py as needed\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    EXP_NAME = config.EXP_NAME\n",
    "    AUTHOR = config.KAGGLE_USERNAME\n",
    "    COMPETITION = config.KAGGLE_COMPETITION_NAME\n",
    "    DATA_PATH = config.COMP_DATASET_DIR\n",
    "    OUTPUT_DIR = config.OUTPUT_DIR\n",
    "    # OOF_DATA_PATH = config.OUTPUT_DIR / \"oof\"\n",
    "    MODEL_PATH = config.OUTPUT_DIR / \"models\"\n",
    "    # SUB_DATA_PATH = config.OUTPUT_DIR / \"submission\"\n",
    "    METHOD_LIST = [\"lightgbm\", \"xgboost\", \"catboost\"]\n",
    "    SEED = 42\n",
    "    n_folds = 5\n",
    "    target_col_list = [\"target\"]\n",
    "    group_col = \"race_group\"  # Required for GroupKFold (edit as needed)\n",
    "    stratified_col = \"race_group\"  # Required for StratifiedKFold (edit as needed)\n",
    "    # metric = \"MAE\"\n",
    "    # metric_maximize_flag = False\n",
    "    num_boost_round = 10000\n",
    "    early_stopping_round = 100\n",
    "    verbose = 250\n",
    "\n",
    "    regression_lgb_params = {\n",
    "        \"objective\": \"regression_l1\",\n",
    "        \"metric\": \"mae\",\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"num_leaves\": 31,\n",
    "        \"seed\": SEED,\n",
    "    }\n",
    "    regression_xgb_params = {\n",
    "        \"objective\": \"reg:absoluteerror\",\n",
    "        \"eval_metric\": \"mae\",\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": 6,\n",
    "        \"random_state\": SEED,\n",
    "    }\n",
    "\n",
    "    regression_cat_params = {\n",
    "        \"loss_function\": \"MAE\",\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"iterations\": num_boost_round,\n",
    "        \"depth\": 7,\n",
    "        \"random_seed\": SEED,\n",
    "    }\n",
    "\n",
    "    model_weight_dict = {\"lightgbm\": 0.40, \"xgboost\": 0.30, \"catboost\": 0.30}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "seed_everything(CFG.SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "train = pl.read_csv(CFG.DATA_PATH / \"train.csv\", try_parse_dates=True)\n",
    "test = pl.read_csv(CFG.DATA_PATH / \"test.csv\", try_parse_dates=True)\n",
    "sample_submission = pl.read_csv(CFG.DATA_PATH / \"sample_submission.csv\")\n",
    "# make index column\n",
    "train = train.with_row_index()\n",
    "test = test.with_row_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Preprocess(ここに前処理や特徴量エンジニアリングを記述)\n",
    "# ====================================================\n",
    "def preprocess(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    output = df.clone()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess(train)\n",
    "test = preprocess(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Make fold column\n",
    "# ====================================================\n",
    "fold_array = np.zeros(len(train))\n",
    "skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.SEED)\n",
    "for i, (_, val_idx) in enumerate(skf.split(train, train[CFG.stratified_col])):\n",
    "    fold = i + 1\n",
    "    fold_array[val_idx] = fold\n",
    "train = train.with_columns(pl.Series(fold_array, dtype=pl.Int8).alias(\"fold\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Set categorical columns etc. (pandas operation from here)\n",
    "# ====================================================\n",
    "train = train.to_pandas()\n",
    "test = test.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Training functions\n",
    "# ====================================================\n",
    "def lightgbm_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    # features: list,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "        params=CFG.regression_lgb_params,\n",
    "        train_set=lgb_train,\n",
    "        num_boost_round=CFG.num_boost_round,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=CFG.early_stopping_round, verbose=CFG.verbose),\n",
    "            lgb.log_evaluation(CFG.verbose),\n",
    "        ],\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def xgboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    # features: list,\n",
    "    # categorical_features: list,\n",
    "):\n",
    "    xgb_train = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
    "    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
    "    model = xgb.train(\n",
    "        CFG.regression_xgb_params,\n",
    "        dtrain=xgb_train,\n",
    "        num_boost_round=CFG.num_boost_round,\n",
    "        evals=[(xgb_train, \"train\"), (xgb_valid, \"eval\")],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose_eval=CFG.verbose,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid, enable_categorical=True))\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def catboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    # features: list,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostRegressor(**CFG.regression_cat_params)\n",
    "    model.fit(\n",
    "        cat_train,\n",
    "        eval_set=[cat_valid],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose=CFG.verbose,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def gradient_boosting_model_cv_training(\n",
    "    method: str, train_df: pd.DataFrame, features: list, categorical_features: list\n",
    "):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions_df = pd.DataFrame(np.zeros((len(train_df), len(CFG.target_col_list))), columns=CFG.target_col_list)\n",
    "    for target_col in CFG.target_col_list:\n",
    "        oof_predictions = np.zeros(len(train_df))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"{method} training fold {fold+1} {target_col}\")\n",
    "            x_train = train_df[train_df[\"fold\"] != fold + 1][features]\n",
    "            y_train = train_df[train_df[\"fold\"] != fold + 1][target_col]\n",
    "            x_valid = train_df[train_df[\"fold\"] == fold + 1][features]\n",
    "            y_valid = train_df[train_df[\"fold\"] == fold + 1][target_col]\n",
    "            if method == \"lightgbm\":\n",
    "                model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            if method == \"xgboost\":\n",
    "                model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid)\n",
    "            if method == \"catboost\":\n",
    "                model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "\n",
    "            # Save best model\n",
    "            pickle.dump(\n",
    "                model,\n",
    "                open(\n",
    "                    CFG.MODEL_DATA_PATH\n",
    "                    / f\"{CFG.AUTHOR}_{method}_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                    \"wb\",\n",
    "                ),\n",
    "            )\n",
    "            # Add to out of folds array\n",
    "            oof_predictions[train_df[\"fold\"] == fold + 1] = valid_pred\n",
    "            del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "            gc.collect()\n",
    "        oof_predictions_df[target_col] = oof_predictions\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    m = score(train_df, oof_predictions_df, \"ID\")\n",
    "    print(f\"{method} our out of folds CV score is {m}\")\n",
    "\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_predictions_df[\"ID\"] = train_df[\"ID\"].values\n",
    "    oof_predictions_df.to_csv(\n",
    "        CFG.OUTPUT_DIR / f\"{CFG.AUTHOR}_oof_{method}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\", index=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: features, categorical_featuresを設定\n",
    "# TODO: 以下のステップ実行さす\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Training\n",
    "# ====================================================\n",
    "for method in CFG.METHOD_LIST:\n",
    "    gradient_boosting_model_cv_training(method, train, features, categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Inference functions\n",
    "# ====================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Inference\n",
    "# ====================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import config  # edit config.py as needed\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import scipy as sp\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from metric import score  # edit metric.py as needed\n",
    "from scipy.stats import rankdata\n",
    "from seed import seed_everything  # edit seed.py as needed\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    DRY_RUN = False\n",
    "    EXP_NAME = config.EXP_NAME\n",
    "    AUTHOR = \"marumarukun\"\n",
    "    COMPETITION = config.KAGGLE_COMPETITION_NAME\n",
    "    DATA_PATH = config.COMP_DATASET_DIR\n",
    "    OUTPUT_DIR = config.OUTPUT_DIR\n",
    "    MODEL_PATH = config.OUTPUT_DIR / \"models\"  # モデル作成・実験時はこちらを使用\n",
    "    # MODEL_PATH = config.ARTIFACT_EXP_DIR(config.EXP_NAME) / \"models\"  # 提出時はこちらを使用\n",
    "    METHOD_LIST = [\"xgboost_cox\", \"catboost_cox\", \"lightgbm\", \"xgboost\", \"catboost\"]\n",
    "    SEED = 42\n",
    "    n_folds = 2 if DRY_RUN else 10\n",
    "    target_col_list = [\"y\"]\n",
    "    cox_target_col_list = [\"efs_time2\"]\n",
    "    # group_col = \"race_group\"  # Required for GroupKFold (edit as needed)\n",
    "    stratified_col = \"race_group_efs\"  # Required for StratifiedKFold (edit as needed)\n",
    "    num_boost_round = 100 if DRY_RUN else 1000000\n",
    "    early_stopping_round = 10 if DRY_RUN else 500  # 10÷lrで設定\n",
    "    verbose = 500\n",
    "\n",
    "    # https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "    # https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "    # https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\n",
    "    regression_lgb_params = {\n",
    "        \"objective\": \"regression\",\n",
    "        # \"metric\": \"mae\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"max_depth\": 5,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"subsample_freq\": 1,\n",
    "        \"seed\": SEED,\n",
    "        \"device\": \"cuda\",  # cpu/gpu/cuda\n",
    "    }\n",
    "    # https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "    # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
    "    # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
    "    regression_xgb_params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        # \"eval_metric\": \"mae\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"max_depth\": 5,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": SEED,\n",
    "        \"device\": \"cuda\",  # cpu/gpu/cuda\n",
    "    }\n",
    "    regression_xgb_cox_params = {\n",
    "        \"objective\": \"survival:cox\",\n",
    "        \"eval_metric\": \"cox-nloglik\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"max_depth\": 3,\n",
    "        \"colsample_bytree\": 0.5,\n",
    "        \"subsample\": 0.8,\n",
    "        \"min_child_weight\": 80,\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": SEED,\n",
    "        \"device\": \"cuda\",  # cpu/gpu/cuda\n",
    "    }\n",
    "    # https://catboost.ai/docs/en/references/training-parameters/\n",
    "    # https://catboost.ai/docs/en/concepts/python-reference_catboostregressor\n",
    "    # https://catboost.ai/docs/en/concepts/python-reference_catboostclassifier\n",
    "    regression_cat_params = {\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"iterations\": num_boost_round,\n",
    "        # \"depth\": 5,\n",
    "        \"grow_policy\": \"Lossguide\",\n",
    "        \"random_seed\": SEED,\n",
    "        \"task_type\": \"GPU\",  # CPU/GPU\n",
    "    }\n",
    "    regression_cat_cox_params = {\n",
    "        \"loss_function\": \"Cox\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"iterations\": num_boost_round,\n",
    "        # \"depth\": 5,\n",
    "        \"grow_policy\": \"Lossguide\",\n",
    "        \"random_seed\": SEED,\n",
    "        \"task_type\": \"CPU\",  # CPU/GPU\n",
    "    }\n",
    "\n",
    "    model_weight_dict = {\"lightgbm\": 0.40, \"xgboost\": 0.30, \"catboost\": 0.30}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "seed_everything(CFG.SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "train = pl.read_csv(CFG.DATA_PATH / \"train.csv\", try_parse_dates=True)\n",
    "test = pl.read_csv(CFG.DATA_PATH / \"test.csv\", try_parse_dates=True)\n",
    "# make index column\n",
    "# train = train.with_row_index()\n",
    "# test = test.with_row_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Preprocess(ここに前処理や特徴量エンジニアリングを記述)\n",
    "# ====================================================\n",
    "def transform_survival_probability(df, time_col=\"efs_time\", event_col=\"efs\"):\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df[time_col], df[event_col])\n",
    "    y = kmf.survival_function_at_times(df[time_col]).values\n",
    "    return y\n",
    "\n",
    "\n",
    "# def preprocess(df: pl.DataFrame) -> pl.DataFrame:\n",
    "#     output = df.clone()\n",
    "#     return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = preprocess(train)\n",
    "# test = preprocess(test)\n",
    "\n",
    "# apply Kaplan-Meier\n",
    "# TODO: もっと適切な目的変数があるかも（人種で層別化してモデル作るとか？）\n",
    "y = transform_survival_probability(train, time_col=\"efs_time\", event_col=\"efs\")\n",
    "train = train.with_columns(pl.Series(y).alias(\"y\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Make fold column\n",
    "# ====================================================\n",
    "# race_group_efs列を作成\n",
    "train = train.with_columns((pl.col(\"race_group\").cast(str) + \"_\" + pl.col(\"efs\").cast(str)).alias(\"race_group_efs\"))\n",
    "\n",
    "fold_array = np.zeros(train.height)\n",
    "skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.SEED)\n",
    "for fold, (_, val_idx) in enumerate(skf.split(train, train[CFG.stratified_col]), start=1):\n",
    "    fold_array[val_idx] = fold\n",
    "train = train.with_columns(pl.Series(fold_array, dtype=pl.Int8).alias(\"fold\"))\n",
    "\n",
    "# fold_array = np.zeros(train.height)\n",
    "# kf = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.SEED)\n",
    "# for fold, (_, val_idx) in enumerate(kf.split(train), start=1):\n",
    "#     fold_array[val_idx] = fold\n",
    "# train = train.with_columns(pl.Series(fold_array, dtype=pl.Int8).alias(\"fold\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.to_pandas()\n",
    "test = test.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'hla_match_c_high', 'hla_high_res_8', 'tbi_status', 'arrhythmia', 'hla_low_res_6', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'hla_high_res_6', 'cmv_status', 'hla_high_res_10', 'hla_match_dqb1_high', 'tce_imm_match', 'hla_nmdp_6', 'hla_match_c_low', 'rituximab', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'year_hct', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hla_match_a_high', 'hepatic_severe', 'donor_age', 'prior_tumor', 'hla_match_b_low', 'peptic_ulcer', 'age_at_hct', 'hla_match_a_low', 'gvhd_proph', 'rheum_issue', 'sex_match', 'hla_match_b_high', 'race_group', 'comorbidity_score', 'karnofsky_score', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'hla_low_res_8', 'cardiac', 'hla_match_drb1_high', 'pulm_moderate', 'hla_low_res_10']\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Set categorical columns etc. (pandas operation from here)\n",
    "# ====================================================\n",
    "RMV = [\"ID\", \"efs\", \"efs_time\", \"y\", \"fold\", \"race_group_efs\"]\n",
    "FEATURES = [c for c in train.columns if c not in RMV]\n",
    "print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In these features, there are 35 CATEGORICAL FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status', 'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe', 'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match', 'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'cardiac', 'pulm_moderate']\n"
     ]
    }
   ],
   "source": [
    "CATS = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype == \"object\":\n",
    "        CATS.append(c)\n",
    "        train[c] = train[c].fillna(\"NAN\")\n",
    "        test[c] = test[c].fillna(\"NAN\")\n",
    "print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We LABEL ENCODE the CATEGORICAL FEATURES: dri_score, psych_disturb, cyto_score, diabetes, tbi_status, arrhythmia, graft_type, vent_hist, renal_issue, pulm_severe, prim_disease_hct, cmv_status, tce_imm_match, rituximab, prod_type, cyto_score_detail, conditioning_intensity, ethnicity, obesity, mrd_hct, in_vivo_tcd, tce_match, hepatic_severe, prior_tumor, peptic_ulcer, gvhd_proph, rheum_issue, sex_match, race_group, hepatic_mild, tce_div_match, donor_related, melphalan_dose, cardiac, pulm_moderate, "
     ]
    }
   ],
   "source": [
    "combined = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "# print(\"Combined data shape:\", combined.shape )\n",
    "\n",
    "# LABEL ENCODE CATEGORICAL FEATURES\n",
    "print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \", end=\"\")\n",
    "for c in FEATURES:\n",
    "    # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "    if c in CATS:\n",
    "        print(f\"{c}, \", end=\"\")\n",
    "        combined[c], _ = combined[c].factorize()\n",
    "        combined[c] -= combined[c].min()\n",
    "        combined[c] = combined[c].astype(\"int32\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "\n",
    "    # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "    else:\n",
    "        if combined[c].dtype == \"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype == \"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "\n",
    "train = combined.iloc[: len(train)].copy()\n",
    "test = combined.iloc[len(train) :].reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Survival Cox model\n",
    "# ====================================================\n",
    "\n",
    "# create cox model's target\n",
    "train[\"efs_time2\"] = train.efs_time.copy()\n",
    "train.loc[train.efs == 0, \"efs_time2\"] *= -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Training functions\n",
    "# ====================================================\n",
    "def lightgbm_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    model = LGBMRegressor(\n",
    "        **CFG.regression_lgb_params,\n",
    "        n_estimators=CFG.num_boost_round,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        categorical_feature=categorical_features,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=CFG.early_stopping_round),\n",
    "            lgb.log_evaluation(CFG.verbose),\n",
    "        ],\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def xgboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "):\n",
    "    model = XGBRegressor(\n",
    "        **CFG.regression_xgb_params,\n",
    "        n_estimators=CFG.num_boost_round,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=CFG.verbose,\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def catboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostRegressor(**CFG.regression_cat_params)\n",
    "    model.fit(\n",
    "        cat_train,\n",
    "        eval_set=[cat_valid],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose=CFG.verbose,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "# Cox models\n",
    "def xgboost_cox_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "):\n",
    "    model = XGBRegressor(\n",
    "        **CFG.regression_xgb_cox_params,\n",
    "        n_estimators=CFG.num_boost_round,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=CFG.verbose,\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def catboost_cox_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostRegressor(**CFG.regression_cat_cox_params)\n",
    "    model.fit(\n",
    "        cat_train,\n",
    "        eval_set=[cat_valid],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose=CFG.verbose,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def gradient_boosting_model_cv_training(\n",
    "    method: str, train_df: pd.DataFrame, target_col_list: list, features: list, categorical_features: list\n",
    "):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions_df = pd.DataFrame(np.zeros((len(train_df), len(target_col_list))), columns=[\"prediction\"])\n",
    "    for target_col in target_col_list:\n",
    "        oof_predictions = np.zeros(len(train_df))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"{method} training fold {fold+1} {target_col}\")\n",
    "            x_train = train_df[train_df[\"fold\"] != fold + 1][features]\n",
    "            y_train = train_df[train_df[\"fold\"] != fold + 1][target_col]\n",
    "            x_valid = train_df[train_df[\"fold\"] == fold + 1][features]\n",
    "            y_valid = train_df[train_df[\"fold\"] == fold + 1][target_col]\n",
    "            if method == \"lightgbm\":\n",
    "                model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            elif method == \"xgboost\":\n",
    "                model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid)\n",
    "            elif method == \"catboost\":\n",
    "                model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            # Cox models\n",
    "            elif method == \"xgboost_cox\":\n",
    "                model, valid_pred = xgboost_cox_training(x_train, y_train, x_valid, y_valid)\n",
    "            elif method == \"catboost_cox\":\n",
    "                model, valid_pred = catboost_cox_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "            # Save best model\n",
    "            save_model_path = (\n",
    "                CFG.MODEL_PATH / f\"{method}_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\"\n",
    "            )\n",
    "            save_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            pickle.dump(\n",
    "                model,\n",
    "                open(\n",
    "                    save_model_path,\n",
    "                    \"wb\",\n",
    "                ),\n",
    "            )\n",
    "            # Add to out of folds array\n",
    "            oof_predictions[train_df[\"fold\"] == fold + 1] = valid_pred\n",
    "            del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "            gc.collect()\n",
    "        # oof_predictions_df[target_col] = oof_predictions\n",
    "\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_predictions_df[\"ID\"] = train_df[\"ID\"].values\n",
    "    oof_predictions_df[\"prediction\"] = oof_predictions\n",
    "    oof_predictions_df.to_csv(CFG.OUTPUT_DIR / f\"oof_{method}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\", index=False)\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    y_true = train_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
    "    m = score(y_true.copy(), oof_predictions_df.copy(), \"ID\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{method} our out of folds CV score is {m}\")\n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "xgboost_cox training fold 1 efs_time2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-cox-nloglik:7.61913\n",
      "[500]\tvalidation_0-cox-nloglik:7.43043\n",
      "[1000]\tvalidation_0-cox-nloglik:7.41832\n",
      "[1500]\tvalidation_0-cox-nloglik:7.41353\n",
      "[2000]\tvalidation_0-cox-nloglik:7.41164\n",
      "[2500]\tvalidation_0-cox-nloglik:7.41018\n",
      "[2938]\tvalidation_0-cox-nloglik:7.41054\n",
      "--------------------------------------------------\n",
      "xgboost_cox training fold 2 efs_time2\n",
      "[0]\tvalidation_0-cox-nloglik:7.61516\n",
      "[500]\tvalidation_0-cox-nloglik:7.42161\n",
      "[1000]\tvalidation_0-cox-nloglik:7.40987\n",
      "[1500]\tvalidation_0-cox-nloglik:7.40566\n",
      "[2000]\tvalidation_0-cox-nloglik:7.40469\n",
      "[2500]\tvalidation_0-cox-nloglik:7.40556\n",
      "[2601]\tvalidation_0-cox-nloglik:7.40647\n",
      "--------------------------------------------------\n",
      "xgboost_cox training fold 3 efs_time2\n",
      "[0]\tvalidation_0-cox-nloglik:7.61993\n",
      "[500]\tvalidation_0-cox-nloglik:7.40966\n",
      "[1000]\tvalidation_0-cox-nloglik:7.39411\n",
      "[1500]\tvalidation_0-cox-nloglik:7.38993\n",
      "[2000]\tvalidation_0-cox-nloglik:7.38700\n",
      "[2500]\tvalidation_0-cox-nloglik:7.38656\n",
      "[2949]\tvalidation_0-cox-nloglik:7.38758\n",
      "--------------------------------------------------\n",
      "xgboost_cox training fold 4 efs_time2\n",
      "[0]\tvalidation_0-cox-nloglik:7.62001\n",
      "[500]\tvalidation_0-cox-nloglik:7.42717\n",
      "[1000]\tvalidation_0-cox-nloglik:7.41271\n",
      "[1500]\tvalidation_0-cox-nloglik:7.40639\n",
      "[2000]\tvalidation_0-cox-nloglik:7.40339\n",
      "[2500]\tvalidation_0-cox-nloglik:7.40177\n",
      "[3000]\tvalidation_0-cox-nloglik:7.40100\n",
      "[3321]\tvalidation_0-cox-nloglik:7.40116\n",
      "--------------------------------------------------\n",
      "xgboost_cox training fold 5 efs_time2\n",
      "[0]\tvalidation_0-cox-nloglik:7.62019\n",
      "[500]\tvalidation_0-cox-nloglik:7.43353\n",
      "[1000]\tvalidation_0-cox-nloglik:7.41995\n",
      "[1500]\tvalidation_0-cox-nloglik:7.41565\n",
      "[2000]\tvalidation_0-cox-nloglik:7.41419\n",
      "[2406]\tvalidation_0-cox-nloglik:7.41483\n",
      "--------------------------------------------------\n",
      "xgboost_cox training fold 6 efs_time2\n",
      "[0]\tvalidation_0-cox-nloglik:7.61935\n",
      "[500]\tvalidation_0-cox-nloglik:7.43009\n",
      "[1000]\tvalidation_0-cox-nloglik:7.42043\n",
      "[1500]\tvalidation_0-cox-nloglik:7.41763\n",
      "[1991]\tvalidation_0-cox-nloglik:7.41809\n",
      "--------------------------------------------------\n",
      "xgboost_cox training fold 7 efs_time2\n",
      "[0]\tvalidation_0-cox-nloglik:7.61899\n",
      "[500]\tvalidation_0-cox-nloglik:7.44351\n",
      "[1000]\tvalidation_0-cox-nloglik:7.43224\n",
      "[1500]\tvalidation_0-cox-nloglik:7.42830\n",
      "[2000]\tvalidation_0-cox-nloglik:7.42703\n",
      "[2339]\tvalidation_0-cox-nloglik:7.42700\n",
      "--------------------------------------------------\n",
      "xgboost_cox training fold 8 efs_time2\n",
      "[0]\tvalidation_0-cox-nloglik:7.61997\n",
      "[500]\tvalidation_0-cox-nloglik:7.39753\n",
      "[1000]\tvalidation_0-cox-nloglik:7.38066\n",
      "[1500]\tvalidation_0-cox-nloglik:7.37542\n",
      "[2000]\tvalidation_0-cox-nloglik:7.37070\n",
      "[2500]\tvalidation_0-cox-nloglik:7.36954\n",
      "[3000]\tvalidation_0-cox-nloglik:7.36873\n",
      "[3500]\tvalidation_0-cox-nloglik:7.36963\n",
      "[3645]\tvalidation_0-cox-nloglik:7.36985\n",
      "--------------------------------------------------\n",
      "xgboost_cox training fold 9 efs_time2\n",
      "[0]\tvalidation_0-cox-nloglik:7.61953\n",
      "[500]\tvalidation_0-cox-nloglik:7.42280\n",
      "[1000]\tvalidation_0-cox-nloglik:7.40970\n",
      "[1500]\tvalidation_0-cox-nloglik:7.40540\n",
      "[2000]\tvalidation_0-cox-nloglik:7.40317\n",
      "[2500]\tvalidation_0-cox-nloglik:7.40239\n",
      "[2988]\tvalidation_0-cox-nloglik:7.40327\n",
      "--------------------------------------------------\n",
      "xgboost_cox training fold 10 efs_time2\n",
      "[0]\tvalidation_0-cox-nloglik:7.61915\n",
      "[500]\tvalidation_0-cox-nloglik:7.42804\n",
      "[1000]\tvalidation_0-cox-nloglik:7.41066\n",
      "[1500]\tvalidation_0-cox-nloglik:7.40290\n",
      "[2000]\tvalidation_0-cox-nloglik:7.39833\n",
      "[2500]\tvalidation_0-cox-nloglik:7.39593\n",
      "[3000]\tvalidation_0-cox-nloglik:7.39538\n",
      "[3500]\tvalidation_0-cox-nloglik:7.39524\n",
      "[4000]\tvalidation_0-cox-nloglik:7.39582\n",
      "[4139]\tvalidation_0-cox-nloglik:7.39625\n",
      "==================================================\n",
      "xgboost_cox our out of folds CV score is 0.6741449356183629\n",
      "==================================================\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 1 efs_time2\n",
      "0:\tlearn: -137189.0597033\ttest: -11838.2650117\tbest: -11838.2650117 (0)\ttotal: 79ms\tremaining: 21h 56m 21s\n",
      "500:\tlearn: -133946.6474756\ttest: -11541.7283884\tbest: -11541.7283884 (500)\ttotal: 8.2s\tremaining: 4h 32m 37s\n",
      "1000:\tlearn: -133190.7073706\ttest: -11519.6554342\tbest: -11519.6554342 (1000)\ttotal: 16.2s\tremaining: 4h 28m 39s\n",
      "1500:\tlearn: -132782.1392125\ttest: -11515.0381597\tbest: -11515.0381597 (1500)\ttotal: 23.9s\tremaining: 4h 25m 8s\n",
      "2000:\tlearn: -132418.3604764\ttest: -11514.5339479\tbest: -11513.9901433 (1944)\ttotal: 31.6s\tremaining: 4h 23m 3s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11513.99014\n",
      "bestIteration = 1944\n",
      "\n",
      "Shrink model to first 1945 iterations.\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 2 efs_time2\n",
      "0:\tlearn: -137196.0229767\ttest: -11831.7141436\tbest: -11831.7141436 (0)\ttotal: 19.5ms\tremaining: 5h 25m 10s\n",
      "500:\tlearn: -133959.1668889\ttest: -11534.6888511\tbest: -11534.6888511 (500)\ttotal: 8.49s\tremaining: 4h 42m 25s\n",
      "1000:\tlearn: -133226.3460488\ttest: -11519.7199705\tbest: -11519.7078334 (997)\ttotal: 16.4s\tremaining: 4h 33m 17s\n",
      "1500:\tlearn: -132772.7753922\ttest: -11515.8720701\tbest: -11515.6915071 (1467)\ttotal: 24.2s\tremaining: 4h 28m 45s\n",
      "2000:\tlearn: -132451.8997703\ttest: -11516.4236930\tbest: -11514.9556729 (1616)\ttotal: 31.9s\tremaining: 4h 25m 20s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11514.95567\n",
      "bestIteration = 1616\n",
      "\n",
      "Shrink model to first 1617 iterations.\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 3 efs_time2\n",
      "0:\tlearn: -137190.7053334\ttest: -11839.6585101\tbest: -11839.6585101 (0)\ttotal: 20.6ms\tremaining: 5h 42m 39s\n",
      "500:\tlearn: -133950.2903302\ttest: -11510.6368761\tbest: -11510.6368761 (500)\ttotal: 8.48s\tremaining: 4h 41m 50s\n",
      "1000:\tlearn: -133185.5921191\ttest: -11493.6889260\tbest: -11493.5236579 (992)\ttotal: 16.7s\tremaining: 4h 37m 20s\n",
      "1500:\tlearn: -132708.2397156\ttest: -11487.9292829\tbest: -11487.7628972 (1495)\ttotal: 24.6s\tremaining: 4h 32m 58s\n",
      "2000:\tlearn: -132362.4758095\ttest: -11486.9980326\tbest: -11486.8856838 (1965)\ttotal: 32.4s\tremaining: 4h 29m 4s\n",
      "2500:\tlearn: -132071.5503724\ttest: -11488.1638818\tbest: -11486.4716813 (2150)\ttotal: 40s\tremaining: 4h 26m 1s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11486.47168\n",
      "bestIteration = 2150\n",
      "\n",
      "Shrink model to first 2151 iterations.\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 4 efs_time2\n",
      "0:\tlearn: -137198.5880592\ttest: -11831.8576447\tbest: -11831.8576447 (0)\ttotal: 19.5ms\tremaining: 5h 24m 30s\n",
      "500:\tlearn: -133959.5920420\ttest: -11535.6987686\tbest: -11535.6987686 (500)\ttotal: 8.37s\tremaining: 4h 38m 26s\n",
      "1000:\tlearn: -133251.0455756\ttest: -11519.1445095\tbest: -11519.1445095 (1000)\ttotal: 16.6s\tremaining: 4h 35m 26s\n",
      "1500:\tlearn: -132832.9139994\ttest: -11516.8612465\tbest: -11516.8307372 (1491)\ttotal: 24.8s\tremaining: 4h 34m 26s\n",
      "2000:\tlearn: -132507.6037075\ttest: -11516.5313641\tbest: -11516.0658144 (1930)\ttotal: 32.4s\tremaining: 4h 29m 23s\n",
      "2500:\tlearn: -132242.4831108\ttest: -11516.5780435\tbest: -11515.3693591 (2296)\ttotal: 40s\tremaining: 4h 25m 42s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11515.36936\n",
      "bestIteration = 2296\n",
      "\n",
      "Shrink model to first 2297 iterations.\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 5 efs_time2\n",
      "0:\tlearn: -137196.6420616\ttest: -11832.3449350\tbest: -11832.3449350 (0)\ttotal: 21.5ms\tremaining: 5h 58m 43s\n",
      "500:\tlearn: -133956.6363737\ttest: -11544.1085838\tbest: -11544.1085838 (500)\ttotal: 8.5s\tremaining: 4h 42m 41s\n",
      "1000:\tlearn: -133174.1541425\ttest: -11531.1221799\tbest: -11531.1221799 (1000)\ttotal: 16.7s\tremaining: 4h 37m 22s\n",
      "1500:\tlearn: -132741.6545419\ttest: -11529.8139695\tbest: -11529.6407651 (1346)\ttotal: 24.7s\tremaining: 4h 33m 25s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11529.64077\n",
      "bestIteration = 1346\n",
      "\n",
      "Shrink model to first 1347 iterations.\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 6 efs_time2\n",
      "0:\tlearn: -137210.0723329\ttest: -11823.1350772\tbest: -11823.1350772 (0)\ttotal: 20.3ms\tremaining: 5h 37m 33s\n",
      "500:\tlearn: -133987.7038373\ttest: -11529.7927978\tbest: -11529.7927978 (500)\ttotal: 8.4s\tremaining: 4h 39m 24s\n",
      "1000:\tlearn: -133244.3600056\ttest: -11520.0223525\tbest: -11519.9796384 (995)\ttotal: 16.5s\tremaining: 4h 34m 32s\n",
      "1500:\tlearn: -132907.1006060\ttest: -11517.6562163\tbest: -11517.2481098 (1407)\ttotal: 24.4s\tremaining: 4h 30m 57s\n",
      "2000:\tlearn: -132599.6454843\ttest: -11517.3527689\tbest: -11516.7586703 (1779)\ttotal: 32.2s\tremaining: 4h 28m 3s\n",
      "2500:\tlearn: -132321.4506824\ttest: -11517.7359180\tbest: -11516.3169489 (2267)\ttotal: 40s\tremaining: 4h 25m 39s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11516.31695\n",
      "bestIteration = 2267\n",
      "\n",
      "Shrink model to first 2268 iterations.\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 7 efs_time2\n",
      "0:\tlearn: -137209.6173728\ttest: -11823.1385469\tbest: -11823.1385469 (0)\ttotal: 25.2ms\tremaining: 7h 22s\n",
      "500:\tlearn: -133935.6361760\ttest: -11547.2515933\tbest: -11547.2515933 (500)\ttotal: 8.78s\tremaining: 4h 51m 50s\n",
      "1000:\tlearn: -133198.1936983\ttest: -11532.8549364\tbest: -11532.8047574 (996)\ttotal: 17.1s\tremaining: 4h 44m 20s\n",
      "1500:\tlearn: -132734.9694836\ttest: -11528.9473439\tbest: -11528.4191433 (1435)\ttotal: 25.5s\tremaining: 4h 42m 16s\n",
      "2000:\tlearn: -132376.2242923\ttest: -11527.6262315\tbest: -11526.8261584 (1772)\ttotal: 33.5s\tremaining: 4h 38m 30s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11526.82616\n",
      "bestIteration = 1772\n",
      "\n",
      "Shrink model to first 1773 iterations.\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 8 efs_time2\n",
      "0:\tlearn: -137208.5946246\ttest: -11823.8461455\tbest: -11823.8461455 (0)\ttotal: 19.2ms\tremaining: 5h 20m 21s\n",
      "500:\tlearn: -134043.2119995\ttest: -11479.5113964\tbest: -11479.5113964 (500)\ttotal: 8.44s\tremaining: 4h 40m 37s\n",
      "1000:\tlearn: -133303.4213215\ttest: -11461.8626182\tbest: -11461.8579064 (980)\ttotal: 16.8s\tremaining: 4h 39m 39s\n",
      "1500:\tlearn: -132887.0889190\ttest: -11458.4289667\tbest: -11458.4289667 (1499)\ttotal: 24.9s\tremaining: 4h 35m 46s\n",
      "2000:\tlearn: -132545.2806522\ttest: -11458.0486729\tbest: -11457.2907601 (1743)\ttotal: 32.8s\tremaining: 4h 32m 23s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11457.29076\n",
      "bestIteration = 1743\n",
      "\n",
      "Shrink model to first 1744 iterations.\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 9 efs_time2\n",
      "0:\tlearn: -137189.7405281\ttest: -11838.5598059\tbest: -11838.5598059 (0)\ttotal: 23.2ms\tremaining: 6h 26m 55s\n",
      "500:\tlearn: -133983.1457184\ttest: -11537.2719094\tbest: -11537.2404873 (496)\ttotal: 8.44s\tremaining: 4h 40m 35s\n",
      "1000:\tlearn: -133208.5851790\ttest: -11524.0384583\tbest: -11524.0384583 (1000)\ttotal: 16.7s\tremaining: 4h 37m 48s\n",
      "1500:\tlearn: -132786.3385191\ttest: -11521.9880767\tbest: -11521.8449209 (1461)\ttotal: 25s\tremaining: 4h 36m 43s\n",
      "2000:\tlearn: -132456.3737496\ttest: -11521.7826585\tbest: -11521.5669929 (1798)\ttotal: 32.9s\tremaining: 4h 33m 10s\n",
      "2500:\tlearn: -132168.2616418\ttest: -11523.0891858\tbest: -11521.4846480 (2205)\ttotal: 40.6s\tremaining: 4h 30m 9s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11521.48465\n",
      "bestIteration = 2205\n",
      "\n",
      "Shrink model to first 2206 iterations.\n",
      "--------------------------------------------------\n",
      "catboost_cox training fold 10 efs_time2\n",
      "0:\tlearn: -137189.4248319\ttest: -11837.8589789\tbest: -11837.8589789 (0)\ttotal: 21ms\tremaining: 5h 50m 49s\n",
      "500:\tlearn: -133969.1527727\ttest: -11544.3699294\tbest: -11544.3095179 (499)\ttotal: 8.39s\tremaining: 4h 38m 54s\n",
      "1000:\tlearn: -133221.7126323\ttest: -11523.5250440\tbest: -11523.4857206 (997)\ttotal: 16.6s\tremaining: 4h 35m 40s\n",
      "1500:\tlearn: -132782.8767632\ttest: -11518.4683225\tbest: -11518.4477756 (1498)\ttotal: 24.6s\tremaining: 4h 32m 33s\n",
      "2000:\tlearn: -132408.9062461\ttest: -11516.7921326\tbest: -11515.3841600 (1922)\ttotal: 32.5s\tremaining: 4h 29m 53s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = -11515.38416\n",
      "bestIteration = 1922\n",
      "\n",
      "Shrink model to first 1923 iterations.\n",
      "==================================================\n",
      "catboost_cox our out of folds CV score is 0.6721245393778973\n",
      "==================================================\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 1 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606188\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0245921\n",
      "[1000]\tvalid_0's l2: 0.0244719\n",
      "[1500]\tvalid_0's l2: 0.0245187\n",
      "Early stopping, best iteration is:\n",
      "[1063]\tvalid_0's l2: 0.0244347\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 2 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606660\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.023826\n",
      "[1000]\tvalid_0's l2: 0.0236613\n",
      "[1500]\tvalid_0's l2: 0.0236155\n",
      "[2000]\tvalid_0's l2: 0.0236236\n",
      "Early stopping, best iteration is:\n",
      "[1522]\tvalid_0's l2: 0.0236098\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 3 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606506\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0236891\n",
      "[1000]\tvalid_0's l2: 0.023369\n",
      "[1500]\tvalid_0's l2: 0.0232763\n",
      "Early stopping, best iteration is:\n",
      "[1415]\tvalid_0's l2: 0.0232605\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 4 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606093\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0246716\n",
      "[1000]\tvalid_0's l2: 0.0243483\n",
      "[1500]\tvalid_0's l2: 0.024273\n",
      "[2000]\tvalid_0's l2: 0.0242549\n",
      "Early stopping, best iteration is:\n",
      "[1948]\tvalid_0's l2: 0.0242465\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 5 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606420\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0244963\n",
      "[1000]\tvalid_0's l2: 0.0243043\n",
      "[1500]\tvalid_0's l2: 0.0243302\n",
      "Early stopping, best iteration is:\n",
      "[1046]\tvalid_0's l2: 0.0242938\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 6 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606450\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0240229\n",
      "[1000]\tvalid_0's l2: 0.0239873\n",
      "Early stopping, best iteration is:\n",
      "[996]\tvalid_0's l2: 0.0239805\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 7 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.605974\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0246723\n",
      "[1000]\tvalid_0's l2: 0.0243958\n",
      "[1500]\tvalid_0's l2: 0.0243765\n",
      "Early stopping, best iteration is:\n",
      "[1177]\tvalid_0's l2: 0.0243516\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 8 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.605772\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0245164\n",
      "[1000]\tvalid_0's l2: 0.0242275\n",
      "[1500]\tvalid_0's l2: 0.0241172\n",
      "[2000]\tvalid_0's l2: 0.0240849\n",
      "[2500]\tvalid_0's l2: 0.024063\n",
      "Early stopping, best iteration is:\n",
      "[2367]\tvalid_0's l2: 0.0240517\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 9 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.606044\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0247282\n",
      "[1000]\tvalid_0's l2: 0.0246007\n",
      "Early stopping, best iteration is:\n",
      "[939]\tvalid_0's l2: 0.0245896\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 10 y\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.605780\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0243474\n",
      "[1000]\tvalid_0's l2: 0.0239341\n",
      "[1500]\tvalid_0's l2: 0.0238411\n",
      "[2000]\tvalid_0's l2: 0.0237919\n",
      "[2500]\tvalid_0's l2: 0.0238246\n",
      "Early stopping, best iteration is:\n",
      "[2082]\tvalid_0's l2: 0.023772\n",
      "==================================================\n",
      "lightgbm our out of folds CV score is 0.6738293563991671\n",
      "==================================================\n",
      "--------------------------------------------------\n",
      "xgboost training fold 1 y\n",
      "[0]\tvalidation_0-rmse:0.17640\n",
      "[500]\tvalidation_0-rmse:0.15710\n",
      "[1000]\tvalidation_0-rmse:0.15601\n",
      "[1500]\tvalidation_0-rmse:0.15572\n",
      "[1863]\tvalidation_0-rmse:0.15586\n",
      "--------------------------------------------------\n",
      "xgboost training fold 2 y\n",
      "[0]\tvalidation_0-rmse:0.17324\n",
      "[500]\tvalidation_0-rmse:0.15471\n",
      "[1000]\tvalidation_0-rmse:0.15377\n",
      "[1500]\tvalidation_0-rmse:0.15368\n",
      "[1591]\tvalidation_0-rmse:0.15377\n",
      "--------------------------------------------------\n",
      "xgboost training fold 3 y\n",
      "[0]\tvalidation_0-rmse:0.17504\n",
      "[500]\tvalidation_0-rmse:0.15435\n",
      "[1000]\tvalidation_0-rmse:0.15320\n",
      "[1500]\tvalidation_0-rmse:0.15307\n",
      "[2000]\tvalidation_0-rmse:0.15307\n",
      "[2315]\tvalidation_0-rmse:0.15330\n",
      "--------------------------------------------------\n",
      "xgboost training fold 4 y\n",
      "[0]\tvalidation_0-rmse:0.17818\n",
      "[500]\tvalidation_0-rmse:0.15740\n",
      "[1000]\tvalidation_0-rmse:0.15593\n",
      "[1500]\tvalidation_0-rmse:0.15562\n",
      "[2000]\tvalidation_0-rmse:0.15573\n",
      "[2089]\tvalidation_0-rmse:0.15571\n",
      "--------------------------------------------------\n",
      "xgboost training fold 5 y\n",
      "[0]\tvalidation_0-rmse:0.17427\n",
      "[500]\tvalidation_0-rmse:0.15682\n",
      "[1000]\tvalidation_0-rmse:0.15637\n",
      "[1500]\tvalidation_0-rmse:0.15618\n",
      "[2000]\tvalidation_0-rmse:0.15636\n",
      "[2014]\tvalidation_0-rmse:0.15638\n",
      "--------------------------------------------------\n",
      "xgboost training fold 6 y\n",
      "[0]\tvalidation_0-rmse:0.17425\n",
      "[500]\tvalidation_0-rmse:0.15526\n",
      "[1000]\tvalidation_0-rmse:0.15466\n",
      "[1500]\tvalidation_0-rmse:0.15471\n",
      "[1552]\tvalidation_0-rmse:0.15479\n",
      "--------------------------------------------------\n",
      "xgboost training fold 7 y\n",
      "[0]\tvalidation_0-rmse:0.17678\n",
      "[500]\tvalidation_0-rmse:0.15787\n",
      "[1000]\tvalidation_0-rmse:0.15684\n",
      "[1500]\tvalidation_0-rmse:0.15681\n",
      "[1829]\tvalidation_0-rmse:0.15690\n",
      "--------------------------------------------------\n",
      "xgboost training fold 8 y\n",
      "[0]\tvalidation_0-rmse:0.17941\n",
      "[500]\tvalidation_0-rmse:0.15720\n",
      "[1000]\tvalidation_0-rmse:0.15587\n",
      "[1500]\tvalidation_0-rmse:0.15533\n",
      "[2000]\tvalidation_0-rmse:0.15533\n",
      "[2310]\tvalidation_0-rmse:0.15543\n",
      "--------------------------------------------------\n",
      "xgboost training fold 9 y\n",
      "[0]\tvalidation_0-rmse:0.17818\n",
      "[500]\tvalidation_0-rmse:0.15773\n",
      "[1000]\tvalidation_0-rmse:0.15670\n",
      "[1500]\tvalidation_0-rmse:0.15672\n",
      "[1956]\tvalidation_0-rmse:0.15684\n",
      "--------------------------------------------------\n",
      "xgboost training fold 10 y\n",
      "[0]\tvalidation_0-rmse:0.17746\n",
      "[500]\tvalidation_0-rmse:0.15703\n",
      "[1000]\tvalidation_0-rmse:0.15513\n",
      "[1500]\tvalidation_0-rmse:0.15472\n",
      "[2000]\tvalidation_0-rmse:0.15476\n",
      "[2176]\tvalidation_0-rmse:0.15472\n",
      "==================================================\n",
      "xgboost our out of folds CV score is 0.6736807950502455\n",
      "==================================================\n",
      "--------------------------------------------------\n",
      "catboost training fold 1 y\n",
      "0:\tlearn: 0.1762574\ttest: 0.1763642\tbest: 0.1763642 (0)\ttotal: 12ms\tremaining: 3h 19m 28s\n",
      "500:\tlearn: 0.1514040\ttest: 0.1580944\tbest: 0.1580901 (497)\ttotal: 5.39s\tremaining: 2h 59m 7s\n",
      "1000:\tlearn: 0.1462454\ttest: 0.1567795\tbest: 0.1567696 (995)\ttotal: 11.5s\tremaining: 3h 11m 32s\n",
      "1500:\tlearn: 0.1423403\ttest: 0.1561779\tbest: 0.1561779 (1500)\ttotal: 17.6s\tremaining: 3h 15m 18s\n",
      "2000:\tlearn: 0.1389337\ttest: 0.1559977\tbest: 0.1559917 (1991)\ttotal: 23.6s\tremaining: 3h 15m 47s\n",
      "2500:\tlearn: 0.1358274\ttest: 0.1557658\tbest: 0.1557644 (2489)\ttotal: 29.8s\tremaining: 3h 18m 21s\n",
      "3000:\tlearn: 0.1330290\ttest: 0.1556006\tbest: 0.1556006 (3000)\ttotal: 36.2s\tremaining: 3h 20m 20s\n",
      "3500:\tlearn: 0.1304273\ttest: 0.1555665\tbest: 0.1555397 (3403)\ttotal: 42.5s\tremaining: 3h 21m 48s\n",
      "4000:\tlearn: 0.1279697\ttest: 0.1555746\tbest: 0.1555354 (3607)\ttotal: 48.2s\tremaining: 3h 19m 49s\n",
      "bestTest = 0.1555353564\n",
      "bestIteration = 3607\n",
      "Shrink model to first 3608 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 2 y\n",
      "0:\tlearn: 0.1766079\ttest: 0.1731950\tbest: 0.1731950 (0)\ttotal: 10.5ms\tremaining: 2h 54m 37s\n",
      "500:\tlearn: 0.1516409\ttest: 0.1556196\tbest: 0.1556196 (500)\ttotal: 5.2s\tremaining: 2h 52m 49s\n",
      "1000:\tlearn: 0.1465572\ttest: 0.1546579\tbest: 0.1546560 (998)\ttotal: 11.1s\tremaining: 3h 4m 13s\n",
      "1500:\tlearn: 0.1428060\ttest: 0.1544039\tbest: 0.1544000 (1483)\ttotal: 17.3s\tremaining: 3h 11m 29s\n",
      "2000:\tlearn: 0.1395824\ttest: 0.1542111\tbest: 0.1541997 (1989)\ttotal: 23.5s\tremaining: 3h 15m 6s\n",
      "2500:\tlearn: 0.1366693\ttest: 0.1541615\tbest: 0.1541090 (2208)\ttotal: 29.3s\tremaining: 3h 14m 42s\n",
      "3000:\tlearn: 0.1339319\ttest: 0.1540378\tbest: 0.1540107 (2911)\ttotal: 34.8s\tremaining: 3h 12m 36s\n",
      "bestTest = 0.1540106972\n",
      "bestIteration = 2911\n",
      "Shrink model to first 2912 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 3 y\n",
      "0:\tlearn: 0.1764100\ttest: 0.1750203\tbest: 0.1750203 (0)\ttotal: 10.6ms\tremaining: 2h 55m 56s\n",
      "500:\tlearn: 0.1515590\ttest: 0.1559517\tbest: 0.1559517 (500)\ttotal: 4.84s\tremaining: 2h 41m 4s\n",
      "1000:\tlearn: 0.1463709\ttest: 0.1546062\tbest: 0.1546052 (998)\ttotal: 10.2s\tremaining: 2h 49m 14s\n",
      "1500:\tlearn: 0.1424641\ttest: 0.1540290\tbest: 0.1540290 (1500)\ttotal: 16s\tremaining: 2h 57m 34s\n",
      "2000:\tlearn: 0.1392329\ttest: 0.1537750\tbest: 0.1537748 (1999)\ttotal: 21.5s\tremaining: 2h 59m 7s\n",
      "2500:\tlearn: 0.1363061\ttest: 0.1536395\tbest: 0.1536154 (2371)\ttotal: 27.5s\tremaining: 3h 2m 28s\n",
      "3000:\tlearn: 0.1336215\ttest: 0.1534833\tbest: 0.1534701 (2935)\ttotal: 33.4s\tremaining: 3h 4m 41s\n",
      "3500:\tlearn: 0.1311468\ttest: 0.1533490\tbest: 0.1533478 (3498)\ttotal: 39.3s\tremaining: 3h 6m 34s\n",
      "4000:\tlearn: 0.1288251\ttest: 0.1533968\tbest: 0.1533408 (3512)\ttotal: 44.9s\tremaining: 3h 6m 15s\n",
      "bestTest = 0.1533407512\n",
      "bestIteration = 3512\n",
      "Shrink model to first 3513 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 4 y\n",
      "0:\tlearn: 0.1760690\ttest: 0.1781163\tbest: 0.1781163 (0)\ttotal: 11.7ms\tremaining: 3h 15m 43s\n",
      "500:\tlearn: 0.1510874\ttest: 0.1586911\tbest: 0.1586911 (500)\ttotal: 4.85s\tremaining: 2h 41m 10s\n",
      "1000:\tlearn: 0.1459270\ttest: 0.1571789\tbest: 0.1571788 (999)\ttotal: 10.1s\tremaining: 2h 47m 59s\n",
      "1500:\tlearn: 0.1420354\ttest: 0.1565381\tbest: 0.1565215 (1449)\ttotal: 15.2s\tremaining: 2h 48m 10s\n",
      "2000:\tlearn: 0.1385255\ttest: 0.1562286\tbest: 0.1562264 (1997)\ttotal: 20.7s\tremaining: 2h 51m 59s\n",
      "2500:\tlearn: 0.1355057\ttest: 0.1560680\tbest: 0.1560679 (2420)\ttotal: 26.1s\tremaining: 2h 53m 38s\n",
      "3000:\tlearn: 0.1326578\ttest: 0.1559009\tbest: 0.1558990 (2974)\ttotal: 31.5s\tremaining: 2h 54m 34s\n",
      "3500:\tlearn: 0.1299860\ttest: 0.1558185\tbest: 0.1558160 (3498)\ttotal: 36.8s\tremaining: 2h 54m 40s\n",
      "4000:\tlearn: 0.1274565\ttest: 0.1558387\tbest: 0.1557971 (3812)\ttotal: 42.3s\tremaining: 2h 55m 37s\n",
      "4500:\tlearn: 0.1250891\ttest: 0.1557286\tbest: 0.1557281 (4499)\ttotal: 48s\tremaining: 2h 57m 3s\n",
      "5000:\tlearn: 0.1228206\ttest: 0.1556312\tbest: 0.1556132 (4955)\ttotal: 53.6s\tremaining: 2h 57m 35s\n",
      "5500:\tlearn: 0.1207176\ttest: 0.1556104\tbest: 0.1555782 (5228)\ttotal: 58.9s\tremaining: 2h 57m 25s\n",
      "bestTest = 0.1555782459\n",
      "bestIteration = 5228\n",
      "Shrink model to first 5229 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 5 y\n",
      "0:\tlearn: 0.1764712\ttest: 0.1742453\tbest: 0.1742453 (0)\ttotal: 8.62ms\tremaining: 2h 23m 44s\n",
      "500:\tlearn: 0.1513068\ttest: 0.1576298\tbest: 0.1576222 (497)\ttotal: 5.14s\tremaining: 2h 51m 6s\n",
      "1000:\tlearn: 0.1460091\ttest: 0.1567704\tbest: 0.1567704 (1000)\ttotal: 10.6s\tremaining: 2h 56m 4s\n",
      "1500:\tlearn: 0.1420287\ttest: 0.1565061\tbest: 0.1565031 (1499)\ttotal: 16.4s\tremaining: 3h 2m 8s\n",
      "2000:\tlearn: 0.1386003\ttest: 0.1564507\tbest: 0.1564272 (1720)\ttotal: 22.2s\tremaining: 3h 4m 16s\n",
      "2500:\tlearn: 0.1354600\ttest: 0.1563974\tbest: 0.1563746 (2160)\ttotal: 28.1s\tremaining: 3h 6m 59s\n",
      "bestTest = 0.1563746485\n",
      "bestIteration = 2160\n",
      "Shrink model to first 2161 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 6 y\n",
      "0:\tlearn: 0.1764928\ttest: 0.1741790\tbest: 0.1741790 (0)\ttotal: 8.5ms\tremaining: 2h 21m 42s\n",
      "500:\tlearn: 0.1517238\ttest: 0.1562509\tbest: 0.1562509 (500)\ttotal: 5.09s\tremaining: 2h 49m 24s\n",
      "1000:\tlearn: 0.1464661\ttest: 0.1552143\tbest: 0.1552037 (989)\ttotal: 10.8s\tremaining: 2h 59m 4s\n",
      "1500:\tlearn: 0.1425822\ttest: 0.1548040\tbest: 0.1548000 (1480)\ttotal: 16.7s\tremaining: 3h 5m 15s\n",
      "2000:\tlearn: 0.1392279\ttest: 0.1546008\tbest: 0.1545900 (1943)\ttotal: 22.5s\tremaining: 3h 6m 58s\n",
      "2500:\tlearn: 0.1362213\ttest: 0.1545118\tbest: 0.1545118 (2500)\ttotal: 28.3s\tremaining: 3h 8m 21s\n",
      "3000:\tlearn: 0.1333962\ttest: 0.1544247\tbest: 0.1544053 (2983)\ttotal: 34.4s\tremaining: 3h 10m 17s\n",
      "3500:\tlearn: 0.1308087\ttest: 0.1543618\tbest: 0.1543593 (3499)\ttotal: 40s\tremaining: 3h 9m 45s\n",
      "4000:\tlearn: 0.1283883\ttest: 0.1544220\tbest: 0.1543486 (3512)\ttotal: 45.3s\tremaining: 3h 8m 4s\n",
      "bestTest = 0.1543485617\n",
      "bestIteration = 3512\n",
      "Shrink model to first 3513 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 7 y\n",
      "0:\tlearn: 0.1762187\ttest: 0.1767416\tbest: 0.1767416 (0)\ttotal: 10.5ms\tremaining: 2h 54m 54s\n",
      "500:\tlearn: 0.1511241\ttest: 0.1591532\tbest: 0.1591528 (497)\ttotal: 5.42s\tremaining: 3h 19s\n",
      "1000:\tlearn: 0.1457585\ttest: 0.1579334\tbest: 0.1579334 (1000)\ttotal: 11.6s\tremaining: 3h 13m 3s\n",
      "1500:\tlearn: 0.1416174\ttest: 0.1574428\tbest: 0.1574374 (1495)\ttotal: 17.7s\tremaining: 3h 16m 15s\n",
      "2000:\tlearn: 0.1382551\ttest: 0.1571568\tbest: 0.1571507 (1991)\ttotal: 23.5s\tremaining: 3h 15m 11s\n",
      "2500:\tlearn: 0.1351986\ttest: 0.1571283\tbest: 0.1571140 (2466)\ttotal: 28.9s\tremaining: 3h 11m 52s\n",
      "bestTest = 0.1571140389\n",
      "bestIteration = 2466\n",
      "Shrink model to first 2467 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 8 y\n",
      "0:\tlearn: 0.1759165\ttest: 0.1793685\tbest: 0.1793685 (0)\ttotal: 9.01ms\tremaining: 2h 30m 9s\n",
      "500:\tlearn: 0.1514031\ttest: 0.1585915\tbest: 0.1585915 (500)\ttotal: 5.24s\tremaining: 2h 54m 22s\n",
      "1000:\tlearn: 0.1462135\ttest: 0.1570863\tbest: 0.1570863 (1000)\ttotal: 11.4s\tremaining: 3h 9m 47s\n",
      "1500:\tlearn: 0.1424485\ttest: 0.1564343\tbest: 0.1564343 (1500)\ttotal: 17.5s\tremaining: 3h 14m 20s\n",
      "2000:\tlearn: 0.1390528\ttest: 0.1561101\tbest: 0.1561101 (2000)\ttotal: 23.4s\tremaining: 3h 14m 45s\n",
      "2500:\tlearn: 0.1360139\ttest: 0.1558643\tbest: 0.1558639 (2498)\ttotal: 29.4s\tremaining: 3h 15m 20s\n",
      "3000:\tlearn: 0.1331948\ttest: 0.1556437\tbest: 0.1556301 (2993)\ttotal: 35.3s\tremaining: 3h 15m 38s\n",
      "3500:\tlearn: 0.1305437\ttest: 0.1556115\tbest: 0.1556013 (3188)\ttotal: 41.3s\tremaining: 3h 15m 50s\n",
      "bestTest = 0.1556013418\n",
      "bestIteration = 3188\n",
      "Shrink model to first 3189 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 9 y\n",
      "0:\tlearn: 0.1760691\ttest: 0.1781318\tbest: 0.1781318 (0)\ttotal: 10.7ms\tremaining: 2h 57m 39s\n",
      "500:\tlearn: 0.1513610\ttest: 0.1589889\tbest: 0.1589876 (499)\ttotal: 5.04s\tremaining: 2h 47m 31s\n",
      "1000:\tlearn: 0.1461674\ttest: 0.1577231\tbest: 0.1577140 (983)\ttotal: 10.8s\tremaining: 2h 59m 35s\n",
      "1500:\tlearn: 0.1421877\ttest: 0.1571637\tbest: 0.1571637 (1500)\ttotal: 16.7s\tremaining: 3h 5m 38s\n",
      "2000:\tlearn: 0.1389087\ttest: 0.1567979\tbest: 0.1567827 (1984)\ttotal: 22.6s\tremaining: 3h 7m 50s\n",
      "2500:\tlearn: 0.1358588\ttest: 0.1567163\tbest: 0.1566914 (2441)\ttotal: 28.5s\tremaining: 3h 9m 42s\n",
      "3000:\tlearn: 0.1330405\ttest: 0.1565323\tbest: 0.1565222 (2974)\ttotal: 34.2s\tremaining: 3h 9m 17s\n",
      "bestTest = 0.156522217\n",
      "bestIteration = 2974\n",
      "Shrink model to first 2975 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 10 y\n",
      "0:\tlearn: 0.1761428\ttest: 0.1773995\tbest: 0.1773995 (0)\ttotal: 10.6ms\tremaining: 2h 57m 19s\n",
      "500:\tlearn: 0.1515856\ttest: 0.1586517\tbest: 0.1586452 (499)\ttotal: 5.44s\tremaining: 3h 45s\n",
      "1000:\tlearn: 0.1465788\ttest: 0.1571166\tbest: 0.1571166 (1000)\ttotal: 11.7s\tremaining: 3h 14m 34s\n",
      "1500:\tlearn: 0.1427820\ttest: 0.1564860\tbest: 0.1564860 (1500)\ttotal: 17.6s\tremaining: 3h 15m 2s\n",
      "2000:\tlearn: 0.1394309\ttest: 0.1559881\tbest: 0.1559749 (1995)\ttotal: 23.3s\tremaining: 3h 13m 59s\n",
      "2500:\tlearn: 0.1365236\ttest: 0.1557087\tbest: 0.1557085 (2499)\ttotal: 28.9s\tremaining: 3h 12m 19s\n",
      "3000:\tlearn: 0.1336657\ttest: 0.1556146\tbest: 0.1556027 (2977)\ttotal: 34.9s\tremaining: 3h 13m 29s\n",
      "3500:\tlearn: 0.1310635\ttest: 0.1555950\tbest: 0.1555568 (3404)\ttotal: 40.9s\tremaining: 3h 13m 53s\n",
      "4000:\tlearn: 0.1286868\ttest: 0.1555302\tbest: 0.1555152 (3727)\ttotal: 46.6s\tremaining: 3h 13m 10s\n",
      "4500:\tlearn: 0.1263854\ttest: 0.1554497\tbest: 0.1554115 (4367)\ttotal: 52.5s\tremaining: 3h 13m 35s\n",
      "5000:\tlearn: 0.1241844\ttest: 0.1553963\tbest: 0.1553644 (4884)\ttotal: 58.4s\tremaining: 3h 13m 42s\n",
      "bestTest = 0.1553643963\n",
      "bestIteration = 4884\n",
      "Shrink model to first 4885 iterations.\n",
      "==================================================\n",
      "catboost our out of folds CV score is 0.6746404518608886\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Training\n",
    "# ====================================================\n",
    "# for method in CFG.METHOD_LIST:\n",
    "#     gradient_boosting_model_cv_training(method, train, CFG.target_col_list, FEATURES, CATS)\n",
    "\n",
    "# Cox models\n",
    "for method in [\"xgboost_cox\", \"catboost_cox\"]:\n",
    "    gradient_boosting_model_cv_training(method, train, CFG.cox_target_col_list, FEATURES, CATS)\n",
    "# Non-Cox models\n",
    "for method in [\"lightgbm\", \"xgboost\", \"catboost\"]:\n",
    "    gradient_boosting_model_cv_training(method, train, CFG.target_col_list, FEATURES, CATS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall CV for Ensemble = 0.6824118119596575\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Overall CV\n",
    "# ====================================================\n",
    "oof_lgb = (\n",
    "    pl.read_csv(CFG.OUTPUT_DIR / f\"oof_lightgbm_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\")\n",
    "    .get_column(\"prediction\")\n",
    "    .to_numpy()\n",
    ")\n",
    "oof_xgb = (\n",
    "    pl.read_csv(CFG.OUTPUT_DIR / f\"oof_xgboost_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\")\n",
    "    .get_column(\"prediction\")\n",
    "    .to_numpy()\n",
    ")\n",
    "oof_cat = (\n",
    "    pl.read_csv(CFG.OUTPUT_DIR / f\"oof_catboost_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\")\n",
    "    .get_column(\"prediction\")\n",
    "    .to_numpy()\n",
    ")\n",
    "# Cox models\n",
    "oof_cox_xgb = (\n",
    "    pl.read_csv(CFG.OUTPUT_DIR / f\"oof_xgboost_cox_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\")\n",
    "    .get_column(\"prediction\")\n",
    "    .to_numpy()\n",
    ")\n",
    "oof_cox_cat = (\n",
    "    pl.read_csv(CFG.OUTPUT_DIR / f\"oof_catboost_cox_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\")\n",
    "    .get_column(\"prediction\")\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "y_true = train[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = (\n",
    "    rankdata(oof_xgb) + rankdata(oof_cat) + rankdata(oof_lgb) + rankdata(oof_cox_xgb) + rankdata(oof_cox_cat)\n",
    ")\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(\"\\nOverall CV for Ensemble =\", m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Inference functions\n",
    "# ====================================================\n",
    "def lightgbm_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"lightgbm_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def xgboost_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"xgboost_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        # pred = model.predict(xgb.DMatrix(x_test, enable_categorical=True))\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def catboost_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"catboost_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "# Cox models\n",
    "def xgboost_cox_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"xgboost_cox_efs_time2_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def catboost_cox_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"catboost_cox_efs_time2_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list, target_col: str):\n",
    "    x_test = test_df[features]\n",
    "    if method == \"lightgbm\":\n",
    "        test_pred = lightgbm_inference(x_test, target_col)\n",
    "    if method == \"xgboost\":\n",
    "        test_pred = xgboost_inference(x_test, target_col)\n",
    "    if method == \"catboost\":\n",
    "        test_pred = catboost_inference(x_test, target_col)\n",
    "    # Cox models\n",
    "    elif method == \"xgboost_cox\":\n",
    "        test_pred = xgboost_cox_inference(x_test, target_col)\n",
    "    elif method == \"catboost_cox\":\n",
    "        test_pred = catboost_cox_inference(x_test, target_col)\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "def predicting(input_df: pd.DataFrame, features: list):\n",
    "    output_df = input_df.copy()\n",
    "    for target_col in CFG.target_col_list:\n",
    "        # output_df[target_col] = 0\n",
    "        for method in CFG.METHOD_LIST:\n",
    "            output_df[f\"{method}_pred_{target_col}\"] = gradient_boosting_model_inference(\n",
    "                method, input_df, features, target_col\n",
    "            )\n",
    "            # output_df[target_col] += CFG.model_weight_dict[method] * output_df[f\"{method}_pred_{target_col}\"]\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28801</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28802</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  prediction\n",
       "0  28800        10.0\n",
       "1  28801        15.0\n",
       "2  28802         5.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Inference\n",
    "# ====================================================\n",
    "output_df = predicting(test, FEATURES)\n",
    "pred_lgb = output_df[\"lightgbm_pred_y\"]\n",
    "pred_xgb = output_df[\"xgboost_pred_y\"]\n",
    "pred_cat = output_df[\"catboost_pred_y\"]\n",
    "# Cox models\n",
    "pred_cox_xgb = output_df[\"xgboost_cox_pred_y\"]\n",
    "pred_cox_cat = output_df[\"catboost_cox_pred_y\"]\n",
    "\n",
    "submission = pd.read_csv(CFG.DATA_PATH / \"sample_submission.csv\")\n",
    "submission[\"prediction\"] = (\n",
    "    rankdata(pred_lgb) + rankdata(pred_xgb) + rankdata(pred_cat) + rankdata(pred_cox_xgb) + rankdata(pred_cox_cat)\n",
    ")\n",
    "submission.to_csv(CFG.OUTPUT_DIR / \"submission.csv\", index=False)\n",
    "print(\"Sub shape:\", submission.shape)\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

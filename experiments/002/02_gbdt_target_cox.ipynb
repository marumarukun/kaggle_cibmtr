{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import config  # edit config.py as needed\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import scipy as sp\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter, NelsonAalenFitter\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from metric import score  # edit metric.py as needed\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import rankdata\n",
    "from seed import seed_everything  # edit seed.py as needed\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    DRY_RUN = False\n",
    "    EXP_NAME = config.EXP_NAME\n",
    "    AUTHOR = \"marumarukun\"\n",
    "    COMPETITION = config.KAGGLE_COMPETITION_NAME\n",
    "    DATA_PATH = config.COMP_DATASET_DIR\n",
    "    OUTPUT_DIR = config.OUTPUT_DIR\n",
    "    MODEL_PATH = config.OUTPUT_DIR / \"models\"  # モデル作成・実験時はこちらを使用\n",
    "    # MODEL_PATH = config.ARTIFACT_EXP_DIR(config.EXP_NAME) / \"models\"  # 提出時はこちらを使用\n",
    "    METHOD_LIST = [\"lightgbm\", \"xgboost\", \"catboost\"]\n",
    "    SEED = 42\n",
    "    n_folds = 2 if DRY_RUN else 10\n",
    "    target_col_list = [\"y_cox\"]\n",
    "    # cox_target_col_list = [\"efs_time2\"]\n",
    "    # group_col = \"race_group\"  # Required for GroupKFold (edit as needed)\n",
    "    stratified_col = \"race_group_efs\"  # Required for StratifiedKFold (edit as needed)\n",
    "    num_boost_round = 100 if DRY_RUN else 1000000\n",
    "    early_stopping_round = 10 if DRY_RUN else 100  # 10÷lrで設定\n",
    "    verbose = 500\n",
    "\n",
    "    # https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "    # https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "    # https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\n",
    "    regression_lgb_params = {\n",
    "        \"objective\": \"regression\",\n",
    "        # \"metric\": \"mae\",\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": 5,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"subsample_freq\": 1,\n",
    "        \"seed\": SEED,\n",
    "        \"device\": \"cuda\",  # cpu/gpu/cuda\n",
    "    }\n",
    "    # https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "    # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
    "    # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
    "    regression_xgb_params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        # \"eval_metric\": \"mae\",\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": 5,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": SEED,\n",
    "        \"device\": \"cuda\",  # cpu/gpu/cuda\n",
    "    }\n",
    "    # https://catboost.ai/docs/en/references/training-parameters/\n",
    "    # https://catboost.ai/docs/en/concepts/python-reference_catboostregressor\n",
    "    # https://catboost.ai/docs/en/concepts/python-reference_catboostclassifier\n",
    "    regression_cat_params = {\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"iterations\": num_boost_round,\n",
    "        # \"depth\": 5,\n",
    "        \"grow_policy\": \"Lossguide\",\n",
    "        \"random_seed\": SEED,\n",
    "        \"task_type\": \"GPU\",  # CPU/GPU\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "seed_everything(CFG.SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "train = pl.read_csv(CFG.DATA_PATH / \"train.csv\", try_parse_dates=True)\n",
    "test = pl.read_csv(CFG.DATA_PATH / \"test.csv\", try_parse_dates=True)\n",
    "# make index column\n",
    "# train = train.with_row_index()\n",
    "# test = test.with_row_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Make fold column\n",
    "# ====================================================\n",
    "# race_group_efs列を作成\n",
    "train = train.with_columns((pl.col(\"race_group\").cast(str) + \"_\" + pl.col(\"efs\").cast(str)).alias(\"race_group_efs\"))\n",
    "\n",
    "fold_array = np.zeros(train.height)\n",
    "skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.SEED)\n",
    "for fold, (_, val_idx) in enumerate(skf.split(train, train[CFG.stratified_col]), start=1):\n",
    "    fold_array[val_idx] = fold\n",
    "train = train.with_columns(pl.Series(fold_array, dtype=pl.Int8).alias(\"fold\"))\n",
    "\n",
    "# fold_array = np.zeros(train.height)\n",
    "# kf = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.SEED)\n",
    "# for fold, (_, val_idx) in enumerate(kf.split(train), start=1):\n",
    "#     fold_array[val_idx] = fold\n",
    "# train = train.with_columns(pl.Series(fold_array, dtype=pl.Int8).alias(\"fold\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.to_pandas()\n",
    "test = test.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'hla_match_c_high', 'hla_high_res_8', 'tbi_status', 'arrhythmia', 'hla_low_res_6', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'hla_high_res_6', 'cmv_status', 'hla_high_res_10', 'hla_match_dqb1_high', 'tce_imm_match', 'hla_nmdp_6', 'hla_match_c_low', 'rituximab', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'year_hct', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hla_match_a_high', 'hepatic_severe', 'donor_age', 'prior_tumor', 'hla_match_b_low', 'peptic_ulcer', 'age_at_hct', 'hla_match_a_low', 'gvhd_proph', 'rheum_issue', 'sex_match', 'hla_match_b_high', 'race_group', 'comorbidity_score', 'karnofsky_score', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'hla_low_res_8', 'cardiac', 'hla_match_drb1_high', 'pulm_moderate', 'hla_low_res_10']\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Set categorical columns etc. (pandas operation from here)\n",
    "# ====================================================\n",
    "RMV = [\"ID\", \"efs\", \"efs_time\", \"y_kaplan\", \"y_nelson\", \"fold\", \"race_group_efs\"]\n",
    "FEATURES = [c for c in train.columns if c not in RMV]\n",
    "print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In these features, there are 35 CATEGORICAL FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status', 'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe', 'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match', 'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'cardiac', 'pulm_moderate']\n"
     ]
    }
   ],
   "source": [
    "CATS = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype == \"object\":\n",
    "        CATS.append(c)\n",
    "        train[c] = train[c].fillna(\"NAN\")\n",
    "        test[c] = test[c].fillna(\"NAN\")\n",
    "print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We LABEL ENCODE the CATEGORICAL FEATURES: dri_score, psych_disturb, cyto_score, diabetes, tbi_status, arrhythmia, graft_type, vent_hist, renal_issue, pulm_severe, prim_disease_hct, cmv_status, tce_imm_match, rituximab, prod_type, cyto_score_detail, conditioning_intensity, ethnicity, obesity, mrd_hct, in_vivo_tcd, tce_match, hepatic_severe, prior_tumor, peptic_ulcer, gvhd_proph, rheum_issue, sex_match, race_group, hepatic_mild, tce_div_match, donor_related, melphalan_dose, cardiac, pulm_moderate, "
     ]
    }
   ],
   "source": [
    "combined = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "# print(\"Combined data shape:\", combined.shape )\n",
    "\n",
    "# LABEL ENCODE CATEGORICAL FEATURES\n",
    "print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \", end=\"\")\n",
    "for c in FEATURES:\n",
    "    # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "    if c in CATS:\n",
    "        print(f\"{c}, \", end=\"\")\n",
    "        combined[c], _ = combined[c].factorize()\n",
    "        combined[c] -= combined[c].min()\n",
    "        combined[c] = combined[c].astype(\"int32\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "\n",
    "    # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "    else:\n",
    "        if combined[c].dtype == \"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype == \"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "\n",
    "train = combined.iloc[: len(train)].copy()\n",
    "test = combined.iloc[len(train) :].reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CoxPHFitter\n",
    "# ====================================================\n",
    "\n",
    "data = train.copy().drop([\"ID\", \"fold\", \"race_group_efs\"], axis=1)\n",
    "\n",
    "# 数値列の欠損を-1で埋める\n",
    "for c in data.columns:\n",
    "    if c not in CATS:\n",
    "        data[c] = data[c].fillna(-1)\n",
    "\n",
    "# カテゴリカル変数のダミー変数化\n",
    "data = pd.get_dummies(data, columns=CATS, drop_first=True)\n",
    "\n",
    "# Drop constant columns if they exist\n",
    "data = data.loc[:, data.nunique() > 1]\n",
    "\n",
    "cph = CoxPHFitter(penalizer=0.01)\n",
    "cph.fit(data, duration_col=\"efs_time\", event_col=\"efs\")\n",
    "\n",
    "train[\"y_cox\"] = cph.predict_partial_hazard(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score of target created by CoxPHFitter = 0.6611743782604956\n"
     ]
    }
   ],
   "source": [
    "y_true = train[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
    "y_target = train[[\"ID\"]].copy()\n",
    "y_target[\"prediction\"] = train[\"y_cox\"]\n",
    "m = score(y_true.copy(), y_target.copy(), \"ID\")\n",
    "print(\"\\nScore of target created by CoxPHFitter =\", m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Training functions\n",
    "# ====================================================\n",
    "def lightgbm_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    model = LGBMRegressor(\n",
    "        **CFG.regression_lgb_params,\n",
    "        n_estimators=CFG.num_boost_round,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        categorical_feature=categorical_features,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=CFG.early_stopping_round),\n",
    "            lgb.log_evaluation(CFG.verbose),\n",
    "        ],\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def xgboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "):\n",
    "    model = XGBRegressor(\n",
    "        **CFG.regression_xgb_params,\n",
    "        n_estimators=CFG.num_boost_round,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=CFG.verbose,\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def catboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostRegressor(**CFG.regression_cat_params)\n",
    "    model.fit(\n",
    "        cat_train,\n",
    "        eval_set=[cat_valid],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose=CFG.verbose,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "# Cox models\n",
    "def xgboost_cox_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "):\n",
    "    model = XGBRegressor(\n",
    "        **CFG.regression_xgb_cox_params,\n",
    "        n_estimators=CFG.num_boost_round,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=CFG.verbose,\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def catboost_cox_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostRegressor(**CFG.regression_cat_cox_params)\n",
    "    model.fit(\n",
    "        cat_train,\n",
    "        eval_set=[cat_valid],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose=CFG.verbose,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def gradient_boosting_model_cv_training(\n",
    "    method: str, train_df: pd.DataFrame, target_col_list: list, features: list, categorical_features: list\n",
    "):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    for target_col in target_col_list:\n",
    "        oof_predictions = np.zeros(len(train_df))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"{method} training fold {fold+1} {target_col}\")\n",
    "            x_train = train_df[train_df[\"fold\"] != fold + 1][features]\n",
    "            y_train = train_df[train_df[\"fold\"] != fold + 1][target_col]\n",
    "            x_valid = train_df[train_df[\"fold\"] == fold + 1][features]\n",
    "            y_valid = train_df[train_df[\"fold\"] == fold + 1][target_col]\n",
    "            if method == \"lightgbm\":\n",
    "                model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            elif method == \"xgboost\":\n",
    "                model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid)\n",
    "            elif method == \"catboost\":\n",
    "                model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            # Cox models\n",
    "            elif method == \"xgboost_cox\":\n",
    "                model, valid_pred = xgboost_cox_training(x_train, y_train, x_valid, y_valid)\n",
    "            elif method == \"catboost_cox\":\n",
    "                model, valid_pred = catboost_cox_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "            # Save best model\n",
    "            save_model_path = (\n",
    "                CFG.MODEL_PATH / f\"{method}_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\"\n",
    "            )\n",
    "            save_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            pickle.dump(\n",
    "                model,\n",
    "                open(\n",
    "                    save_model_path,\n",
    "                    \"wb\",\n",
    "                ),\n",
    "            )\n",
    "            # Add to out of folds array\n",
    "            oof_predictions[train_df[\"fold\"] == fold + 1] = valid_pred\n",
    "            del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "            gc.collect()\n",
    "\n",
    "        # Create a dataframe to store out of folds predictions\n",
    "        oof_predictions_df = pd.DataFrame()\n",
    "        oof_predictions_df[\"ID\"] = train_df[\"ID\"].values\n",
    "        oof_predictions_df[\"prediction\"] = oof_predictions\n",
    "        oof_predictions_df.to_csv(\n",
    "            CFG.OUTPUT_DIR / f\"oof_{method}_{target_col}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\", index=False\n",
    "        )\n",
    "\n",
    "        # Compute out of folds metric\n",
    "        y_true = train_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
    "        m = score(y_true.copy(), oof_predictions_df.copy(), \"ID\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"{method} our out of folds CV score is {m}\")\n",
    "        print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 1 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.252319\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.024522\n",
      "[1000]\tvalid_0's l2: 0.0215682\n",
      "[1500]\tvalid_0's l2: 0.0206188\n",
      "[2000]\tvalid_0's l2: 0.0202072\n",
      "[2500]\tvalid_0's l2: 0.0199824\n",
      "[3000]\tvalid_0's l2: 0.0198793\n",
      "[3500]\tvalid_0's l2: 0.0197956\n",
      "[4000]\tvalid_0's l2: 0.0197351\n",
      "[4500]\tvalid_0's l2: 0.0197091\n",
      "[5000]\tvalid_0's l2: 0.01969\n",
      "[5500]\tvalid_0's l2: 0.0196741\n",
      "[6000]\tvalid_0's l2: 0.0196575\n",
      "Early stopping, best iteration is:\n",
      "[6045]\tvalid_0's l2: 0.0196558\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 2 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.251570\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0252116\n",
      "[1000]\tvalid_0's l2: 0.0223704\n",
      "[1500]\tvalid_0's l2: 0.0215482\n",
      "[2000]\tvalid_0's l2: 0.0211125\n",
      "[2500]\tvalid_0's l2: 0.0208382\n",
      "[3000]\tvalid_0's l2: 0.0207316\n",
      "[3500]\tvalid_0's l2: 0.020646\n",
      "Early stopping, best iteration is:\n",
      "[3758]\tvalid_0's l2: 0.0206255\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 3 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.252552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0268817\n",
      "[1000]\tvalid_0's l2: 0.0239736\n",
      "[1500]\tvalid_0's l2: 0.0230534\n",
      "[2000]\tvalid_0's l2: 0.0225954\n",
      "[2500]\tvalid_0's l2: 0.0223349\n",
      "[3000]\tvalid_0's l2: 0.0221842\n",
      "[3500]\tvalid_0's l2: 0.0221037\n",
      "[4000]\tvalid_0's l2: 0.0220423\n",
      "Early stopping, best iteration is:\n",
      "[4068]\tvalid_0's l2: 0.0220352\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 4 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.250250\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0302831\n",
      "[1000]\tvalid_0's l2: 0.0271394\n",
      "[1500]\tvalid_0's l2: 0.0261188\n",
      "[2000]\tvalid_0's l2: 0.025658\n",
      "[2500]\tvalid_0's l2: 0.0254252\n",
      "[3000]\tvalid_0's l2: 0.0252725\n",
      "[3500]\tvalid_0's l2: 0.0251705\n",
      "[4000]\tvalid_0's l2: 0.0251025\n",
      "[4500]\tvalid_0's l2: 0.0250619\n",
      "[5000]\tvalid_0's l2: 0.0250329\n",
      "[5500]\tvalid_0's l2: 0.0250113\n",
      "[6000]\tvalid_0's l2: 0.0250002\n",
      "Early stopping, best iteration is:\n",
      "[5931]\tvalid_0's l2: 0.0249988\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 5 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.250879\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0260261\n",
      "[1000]\tvalid_0's l2: 0.0230439\n",
      "[1500]\tvalid_0's l2: 0.0219648\n",
      "[2000]\tvalid_0's l2: 0.0215205\n",
      "[2500]\tvalid_0's l2: 0.0212511\n",
      "[3000]\tvalid_0's l2: 0.0211124\n",
      "[3500]\tvalid_0's l2: 0.0210036\n",
      "[4000]\tvalid_0's l2: 0.0209446\n",
      "[4500]\tvalid_0's l2: 0.0208938\n",
      "Early stopping, best iteration is:\n",
      "[4758]\tvalid_0's l2: 0.0208775\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 6 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.253690\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.025153\n",
      "[1000]\tvalid_0's l2: 0.0222673\n",
      "[1500]\tvalid_0's l2: 0.0214636\n",
      "[2000]\tvalid_0's l2: 0.0209924\n",
      "[2500]\tvalid_0's l2: 0.0208021\n",
      "[3000]\tvalid_0's l2: 0.0206862\n",
      "[3500]\tvalid_0's l2: 0.0206343\n",
      "[4000]\tvalid_0's l2: 0.0205918\n",
      "[4500]\tvalid_0's l2: 0.0205594\n",
      "Early stopping, best iteration is:\n",
      "[4867]\tvalid_0's l2: 0.0205404\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 7 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.248712\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.032266\n",
      "[1000]\tvalid_0's l2: 0.029066\n",
      "[1500]\tvalid_0's l2: 0.0281382\n",
      "[2000]\tvalid_0's l2: 0.0276144\n",
      "[2500]\tvalid_0's l2: 0.0273949\n",
      "[3000]\tvalid_0's l2: 0.0272346\n",
      "[3500]\tvalid_0's l2: 0.0271311\n",
      "[4000]\tvalid_0's l2: 0.027058\n",
      "Early stopping, best iteration is:\n",
      "[4132]\tvalid_0's l2: 0.0270485\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 8 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.253610\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0274977\n",
      "[1000]\tvalid_0's l2: 0.0245054\n",
      "[1500]\tvalid_0's l2: 0.023721\n",
      "[2000]\tvalid_0's l2: 0.0234174\n",
      "[2500]\tvalid_0's l2: 0.0232331\n",
      "[3000]\tvalid_0's l2: 0.0231047\n",
      "[3500]\tvalid_0's l2: 0.0230163\n",
      "[4000]\tvalid_0's l2: 0.0229498\n",
      "[4500]\tvalid_0's l2: 0.0229143\n",
      "[5000]\tvalid_0's l2: 0.0228996\n",
      "[5500]\tvalid_0's l2: 0.0228812\n",
      "Early stopping, best iteration is:\n",
      "[5685]\tvalid_0's l2: 0.0228759\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 9 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.252937\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0307827\n",
      "[1000]\tvalid_0's l2: 0.0272421\n",
      "[1500]\tvalid_0's l2: 0.0261847\n",
      "[2000]\tvalid_0's l2: 0.0256332\n",
      "[2500]\tvalid_0's l2: 0.0254234\n",
      "[3000]\tvalid_0's l2: 0.0252923\n",
      "[3500]\tvalid_0's l2: 0.0252099\n",
      "[4000]\tvalid_0's l2: 0.025149\n",
      "[4500]\tvalid_0's l2: 0.0251118\n",
      "Early stopping, best iteration is:\n",
      "[4425]\tvalid_0's l2: 0.0251079\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 10 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.251124\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\tvalid_0's l2: 0.0263697\n",
      "[1000]\tvalid_0's l2: 0.0233785\n",
      "[1500]\tvalid_0's l2: 0.0224925\n",
      "[2000]\tvalid_0's l2: 0.0221202\n",
      "[2500]\tvalid_0's l2: 0.0219042\n",
      "[3000]\tvalid_0's l2: 0.0217595\n",
      "[3500]\tvalid_0's l2: 0.0217068\n",
      "[4000]\tvalid_0's l2: 0.0216593\n",
      "[4500]\tvalid_0's l2: 0.0216316\n",
      "[5000]\tvalid_0's l2: 0.0216125\n",
      "[5500]\tvalid_0's l2: 0.0215921\n",
      "Early stopping, best iteration is:\n",
      "[5403]\tvalid_0's l2: 0.0215902\n",
      "==================================================\n",
      "lightgbm our out of folds CV score is 0.6591912123045328\n",
      "==================================================\n",
      "--------------------------------------------------\n",
      "xgboost training fold 1 y_cox\n",
      "[0]\tvalidation_0-rmse:0.77497\n",
      "[500]\tvalidation_0-rmse:0.15926\n",
      "[1000]\tvalidation_0-rmse:0.14158\n",
      "[1500]\tvalidation_0-rmse:0.13562\n",
      "[2000]\tvalidation_0-rmse:0.13258\n",
      "[2500]\tvalidation_0-rmse:0.13097\n",
      "[3000]\tvalidation_0-rmse:0.12978\n",
      "[3181]\tvalidation_0-rmse:0.12963\n",
      "--------------------------------------------------\n",
      "xgboost training fold 2 y_cox\n",
      "[0]\tvalidation_0-rmse:0.85802\n",
      "[500]\tvalidation_0-rmse:0.17137\n",
      "[1000]\tvalidation_0-rmse:0.15335\n",
      "[1500]\tvalidation_0-rmse:0.14732\n",
      "[2000]\tvalidation_0-rmse:0.14439\n",
      "[2500]\tvalidation_0-rmse:0.14263\n",
      "[3000]\tvalidation_0-rmse:0.14153\n",
      "[3500]\tvalidation_0-rmse:0.14090\n",
      "[4000]\tvalidation_0-rmse:0.14045\n",
      "[4500]\tvalidation_0-rmse:0.14005\n",
      "[5000]\tvalidation_0-rmse:0.13979\n",
      "[5500]\tvalidation_0-rmse:0.13963\n",
      "[5942]\tvalidation_0-rmse:0.13953\n",
      "--------------------------------------------------\n",
      "xgboost training fold 3 y_cox\n",
      "[0]\tvalidation_0-rmse:0.80420\n",
      "[500]\tvalidation_0-rmse:0.16851\n",
      "[1000]\tvalidation_0-rmse:0.14888\n",
      "[1500]\tvalidation_0-rmse:0.14261\n",
      "[2000]\tvalidation_0-rmse:0.13954\n",
      "[2500]\tvalidation_0-rmse:0.13825\n",
      "[3000]\tvalidation_0-rmse:0.13701\n",
      "[3500]\tvalidation_0-rmse:0.13629\n",
      "[4000]\tvalidation_0-rmse:0.13581\n",
      "[4500]\tvalidation_0-rmse:0.13546\n",
      "[5000]\tvalidation_0-rmse:0.13530\n",
      "[5500]\tvalidation_0-rmse:0.13509\n",
      "[5799]\tvalidation_0-rmse:0.13503\n",
      "--------------------------------------------------\n",
      "xgboost training fold 4 y_cox\n",
      "[0]\tvalidation_0-rmse:0.81818\n",
      "[500]\tvalidation_0-rmse:0.17967\n",
      "[1000]\tvalidation_0-rmse:0.15974\n",
      "[1500]\tvalidation_0-rmse:0.15381\n",
      "[2000]\tvalidation_0-rmse:0.15127\n",
      "[2500]\tvalidation_0-rmse:0.14962\n",
      "[3000]\tvalidation_0-rmse:0.14872\n",
      "[3500]\tvalidation_0-rmse:0.14809\n",
      "[4000]\tvalidation_0-rmse:0.14766\n",
      "[4500]\tvalidation_0-rmse:0.14734\n",
      "[5000]\tvalidation_0-rmse:0.14709\n",
      "[5500]\tvalidation_0-rmse:0.14688\n",
      "[6000]\tvalidation_0-rmse:0.14673\n",
      "[6500]\tvalidation_0-rmse:0.14660\n",
      "[7000]\tvalidation_0-rmse:0.14652\n",
      "[7500]\tvalidation_0-rmse:0.14644\n",
      "[7865]\tvalidation_0-rmse:0.14641\n",
      "--------------------------------------------------\n",
      "xgboost training fold 5 y_cox\n",
      "[0]\tvalidation_0-rmse:0.80960\n",
      "[500]\tvalidation_0-rmse:0.16004\n",
      "[1000]\tvalidation_0-rmse:0.14180\n",
      "[1500]\tvalidation_0-rmse:0.13619\n",
      "[2000]\tvalidation_0-rmse:0.13347\n",
      "[2500]\tvalidation_0-rmse:0.13218\n",
      "[3000]\tvalidation_0-rmse:0.13136\n",
      "[3500]\tvalidation_0-rmse:0.13082\n",
      "[4000]\tvalidation_0-rmse:0.13041\n",
      "[4500]\tvalidation_0-rmse:0.13010\n",
      "[5000]\tvalidation_0-rmse:0.12991\n",
      "[5500]\tvalidation_0-rmse:0.12978\n",
      "[6000]\tvalidation_0-rmse:0.12967\n",
      "[6500]\tvalidation_0-rmse:0.12956\n",
      "[6659]\tvalidation_0-rmse:0.12955\n",
      "--------------------------------------------------\n",
      "xgboost training fold 6 y_cox\n",
      "[0]\tvalidation_0-rmse:0.78186\n",
      "[500]\tvalidation_0-rmse:0.15893\n",
      "[1000]\tvalidation_0-rmse:0.14177\n",
      "[1500]\tvalidation_0-rmse:0.13614\n",
      "[2000]\tvalidation_0-rmse:0.13363\n",
      "[2500]\tvalidation_0-rmse:0.13244\n",
      "[3000]\tvalidation_0-rmse:0.13145\n",
      "[3500]\tvalidation_0-rmse:0.13076\n",
      "[4000]\tvalidation_0-rmse:0.13027\n",
      "[4500]\tvalidation_0-rmse:0.13000\n",
      "[4610]\tvalidation_0-rmse:0.13000\n",
      "--------------------------------------------------\n",
      "xgboost training fold 7 y_cox\n",
      "[0]\tvalidation_0-rmse:0.84974\n",
      "[500]\tvalidation_0-rmse:0.18734\n",
      "[1000]\tvalidation_0-rmse:0.16763\n",
      "[1500]\tvalidation_0-rmse:0.16138\n",
      "[2000]\tvalidation_0-rmse:0.15826\n",
      "[2500]\tvalidation_0-rmse:0.15670\n",
      "[3000]\tvalidation_0-rmse:0.15562\n",
      "[3500]\tvalidation_0-rmse:0.15497\n",
      "[4000]\tvalidation_0-rmse:0.15445\n",
      "[4500]\tvalidation_0-rmse:0.15418\n",
      "[5000]\tvalidation_0-rmse:0.15391\n",
      "[5500]\tvalidation_0-rmse:0.15371\n",
      "[6000]\tvalidation_0-rmse:0.15358\n",
      "[6500]\tvalidation_0-rmse:0.15347\n",
      "[7000]\tvalidation_0-rmse:0.15340\n",
      "[7320]\tvalidation_0-rmse:0.15338\n",
      "--------------------------------------------------\n",
      "xgboost training fold 8 y_cox\n",
      "[0]\tvalidation_0-rmse:0.83018\n",
      "[500]\tvalidation_0-rmse:0.17368\n",
      "[1000]\tvalidation_0-rmse:0.15481\n",
      "[1500]\tvalidation_0-rmse:0.14879\n",
      "[2000]\tvalidation_0-rmse:0.14601\n",
      "[2500]\tvalidation_0-rmse:0.14449\n",
      "[3000]\tvalidation_0-rmse:0.14359\n",
      "[3500]\tvalidation_0-rmse:0.14303\n",
      "[4000]\tvalidation_0-rmse:0.14263\n",
      "[4500]\tvalidation_0-rmse:0.14241\n",
      "[5000]\tvalidation_0-rmse:0.14215\n",
      "[5500]\tvalidation_0-rmse:0.14196\n",
      "[6000]\tvalidation_0-rmse:0.14192\n",
      "[6500]\tvalidation_0-rmse:0.14182\n",
      "[6640]\tvalidation_0-rmse:0.14182\n",
      "--------------------------------------------------\n",
      "xgboost training fold 9 y_cox\n",
      "[0]\tvalidation_0-rmse:0.83565\n",
      "[500]\tvalidation_0-rmse:0.17633\n",
      "[1000]\tvalidation_0-rmse:0.15511\n",
      "[1500]\tvalidation_0-rmse:0.14910\n",
      "[2000]\tvalidation_0-rmse:0.14571\n",
      "[2500]\tvalidation_0-rmse:0.14372\n",
      "[3000]\tvalidation_0-rmse:0.14265\n",
      "[3500]\tvalidation_0-rmse:0.14183\n",
      "[4000]\tvalidation_0-rmse:0.14129\n",
      "[4500]\tvalidation_0-rmse:0.14099\n",
      "[5000]\tvalidation_0-rmse:0.14070\n",
      "[5500]\tvalidation_0-rmse:0.14048\n",
      "[6000]\tvalidation_0-rmse:0.14034\n",
      "[6404]\tvalidation_0-rmse:0.14027\n",
      "--------------------------------------------------\n",
      "xgboost training fold 10 y_cox\n",
      "[0]\tvalidation_0-rmse:0.82247\n",
      "[500]\tvalidation_0-rmse:0.15870\n",
      "[1000]\tvalidation_0-rmse:0.14157\n",
      "[1500]\tvalidation_0-rmse:0.13604\n",
      "[2000]\tvalidation_0-rmse:0.13346\n",
      "[2500]\tvalidation_0-rmse:0.13216\n",
      "[3000]\tvalidation_0-rmse:0.13116\n",
      "[3500]\tvalidation_0-rmse:0.13054\n",
      "[4000]\tvalidation_0-rmse:0.13017\n",
      "[4500]\tvalidation_0-rmse:0.12983\n",
      "[5000]\tvalidation_0-rmse:0.12957\n",
      "[5500]\tvalidation_0-rmse:0.12938\n",
      "[6000]\tvalidation_0-rmse:0.12922\n",
      "[6500]\tvalidation_0-rmse:0.12913\n",
      "[6697]\tvalidation_0-rmse:0.12911\n",
      "==================================================\n",
      "xgboost our out of folds CV score is 0.6597448328912736\n",
      "==================================================\n",
      "--------------------------------------------------\n",
      "catboost training fold 1 y_cox\n",
      "0:\tlearn: 0.8180344\ttest: 0.7697745\tbest: 0.7697745 (0)\ttotal: 19.8ms\tremaining: 5h 30m\n",
      "500:\tlearn: 0.1219365\ttest: 0.1640415\tbest: 0.1640415 (500)\ttotal: 6.04s\tremaining: 3h 21m\n",
      "1000:\tlearn: 0.0913745\ttest: 0.1458436\tbest: 0.1458436 (1000)\ttotal: 13.4s\tremaining: 3h 42m 34s\n",
      "1500:\tlearn: 0.0759323\ttest: 0.1372576\tbest: 0.1372576 (1500)\ttotal: 22s\tremaining: 4h 4m 1s\n",
      "2000:\tlearn: 0.0665762\ttest: 0.1336647\tbest: 0.1336490 (1992)\ttotal: 30.6s\tremaining: 4h 14m 41s\n",
      "2500:\tlearn: 0.0594988\ttest: 0.1303671\tbest: 0.1303671 (2500)\ttotal: 39.2s\tremaining: 4h 20m 39s\n",
      "3000:\tlearn: 0.0539598\ttest: 0.1282021\tbest: 0.1282021 (3000)\ttotal: 47.8s\tremaining: 4h 24m 48s\n",
      "3500:\tlearn: 0.0496362\ttest: 0.1266928\tbest: 0.1266855 (3493)\ttotal: 55.3s\tremaining: 4h 22m 33s\n",
      "4000:\tlearn: 0.0459792\ttest: 0.1257378\tbest: 0.1257378 (4000)\ttotal: 1m 1s\tremaining: 4h 13m 10s\n",
      "4500:\tlearn: 0.0429201\ttest: 0.1248475\tbest: 0.1248352 (4499)\ttotal: 1m 7s\tremaining: 4h 8m 6s\n",
      "5000:\tlearn: 0.0402696\ttest: 0.1241066\tbest: 0.1241043 (4992)\ttotal: 1m 13s\tremaining: 4h 2m 44s\n",
      "bestTest = 0.1238776952\n",
      "bestIteration = 5219\n",
      "Shrink model to first 5220 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 2 y_cox\n",
      "0:\tlearn: 0.8099680\ttest: 0.8534276\tbest: 0.8534276 (0)\ttotal: 16.7ms\tremaining: 4h 37m 47s\n",
      "500:\tlearn: 0.1226165\ttest: 0.1801363\tbest: 0.1801363 (500)\ttotal: 6.57s\tremaining: 3h 38m 27s\n",
      "1000:\tlearn: 0.0920595\ttest: 0.1587303\tbest: 0.1587186 (998)\ttotal: 13.4s\tremaining: 3h 42m 20s\n",
      "1500:\tlearn: 0.0770896\ttest: 0.1503836\tbest: 0.1503826 (1499)\ttotal: 19.5s\tremaining: 3h 36m 35s\n",
      "2000:\tlearn: 0.0673759\ttest: 0.1453735\tbest: 0.1453735 (2000)\ttotal: 25.7s\tremaining: 3h 33m 23s\n",
      "2500:\tlearn: 0.0602655\ttest: 0.1424025\tbest: 0.1423974 (2498)\ttotal: 31.3s\tremaining: 3h 28m 21s\n",
      "3000:\tlearn: 0.0546591\ttest: 0.1401100\tbest: 0.1401100 (3000)\ttotal: 37.4s\tremaining: 3h 27m 13s\n",
      "3500:\tlearn: 0.0503075\ttest: 0.1387043\tbest: 0.1386998 (3499)\ttotal: 43.5s\tremaining: 3h 26m 8s\n",
      "4000:\tlearn: 0.0466779\ttest: 0.1373604\tbest: 0.1373552 (3997)\ttotal: 48.6s\tremaining: 3h 21m 49s\n",
      "4500:\tlearn: 0.0436559\ttest: 0.1365132\tbest: 0.1365132 (4500)\ttotal: 53.8s\tremaining: 3h 18m 23s\n",
      "5000:\tlearn: 0.0409219\ttest: 0.1357294\tbest: 0.1357294 (5000)\ttotal: 59.6s\tremaining: 3h 17m 47s\n",
      "5500:\tlearn: 0.0385753\ttest: 0.1350783\tbest: 0.1350715 (5495)\ttotal: 1m 5s\tremaining: 3h 17m 21s\n",
      "6000:\tlearn: 0.0365213\ttest: 0.1346590\tbest: 0.1346546 (5984)\ttotal: 1m 11s\tremaining: 3h 16m\n",
      "6500:\tlearn: 0.0346134\ttest: 0.1342945\tbest: 0.1342913 (6498)\ttotal: 1m 16s\tremaining: 3h 15m 21s\n",
      "7000:\tlearn: 0.0329251\ttest: 0.1338321\tbest: 0.1338318 (6993)\ttotal: 1m 22s\tremaining: 3h 15m 3s\n",
      "7500:\tlearn: 0.0313959\ttest: 0.1335338\tbest: 0.1335320 (7496)\ttotal: 1m 28s\tremaining: 3h 15m 38s\n",
      "8000:\tlearn: 0.0300210\ttest: 0.1332154\tbest: 0.1332129 (7998)\ttotal: 1m 34s\tremaining: 3h 15m 40s\n",
      "8500:\tlearn: 0.0287375\ttest: 0.1330221\tbest: 0.1330212 (8498)\ttotal: 1m 40s\tremaining: 3h 14m 45s\n",
      "9000:\tlearn: 0.0275759\ttest: 0.1327840\tbest: 0.1327840 (9000)\ttotal: 1m 46s\tremaining: 3h 15m 6s\n",
      "9500:\tlearn: 0.0264906\ttest: 0.1325996\tbest: 0.1325996 (9500)\ttotal: 1m 52s\tremaining: 3h 14m 52s\n",
      "10000:\tlearn: 0.0254607\ttest: 0.1324278\tbest: 0.1324278 (10000)\ttotal: 1m 57s\tremaining: 3h 14m 40s\n",
      "10500:\tlearn: 0.0245045\ttest: 0.1322723\tbest: 0.1322716 (10499)\ttotal: 2m 4s\tremaining: 3h 15m 18s\n",
      "11000:\tlearn: 0.0236006\ttest: 0.1321147\tbest: 0.1321129 (10990)\ttotal: 2m 9s\tremaining: 3h 14m 26s\n",
      "11500:\tlearn: 0.0227402\ttest: 0.1319446\tbest: 0.1319440 (11497)\ttotal: 2m 15s\tremaining: 3h 14m 5s\n",
      "12000:\tlearn: 0.0219564\ttest: 0.1318102\tbest: 0.1318075 (11995)\ttotal: 2m 21s\tremaining: 3h 14m 3s\n",
      "12500:\tlearn: 0.0212219\ttest: 0.1316556\tbest: 0.1316532 (12495)\ttotal: 2m 27s\tremaining: 3h 13m 51s\n",
      "bestTest = 0.1316330895\n",
      "bestIteration = 12564\n",
      "Shrink model to first 12565 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 3 y_cox\n",
      "0:\tlearn: 0.8152959\ttest: 0.8002405\tbest: 0.8002405 (0)\ttotal: 17.3ms\tremaining: 4h 48m 1s\n",
      "500:\tlearn: 0.1185880\ttest: 0.1800518\tbest: 0.1800518 (500)\ttotal: 5.24s\tremaining: 2h 54m 6s\n",
      "1000:\tlearn: 0.0897099\ttest: 0.1609692\tbest: 0.1609498 (999)\ttotal: 10.8s\tremaining: 2h 59m 51s\n",
      "1500:\tlearn: 0.0749997\ttest: 0.1521864\tbest: 0.1521864 (1500)\ttotal: 16.7s\tremaining: 3h 4m 43s\n",
      "2000:\tlearn: 0.0654445\ttest: 0.1468993\tbest: 0.1468993 (2000)\ttotal: 22.8s\tremaining: 3h 9m 40s\n",
      "2500:\tlearn: 0.0585393\ttest: 0.1443081\tbest: 0.1442939 (2497)\ttotal: 28.8s\tremaining: 3h 11m 17s\n",
      "3000:\tlearn: 0.0531413\ttest: 0.1420435\tbest: 0.1420435 (3000)\ttotal: 34.4s\tremaining: 3h 10m 32s\n",
      "3500:\tlearn: 0.0487673\ttest: 0.1402732\tbest: 0.1402732 (3500)\ttotal: 40.3s\tremaining: 3h 11m 1s\n",
      "4000:\tlearn: 0.0451804\ttest: 0.1388578\tbest: 0.1388578 (4000)\ttotal: 46.8s\tremaining: 3h 14m 6s\n",
      "4500:\tlearn: 0.0421029\ttest: 0.1378982\tbest: 0.1378982 (4500)\ttotal: 52.8s\tremaining: 3h 14m 34s\n",
      "5000:\tlearn: 0.0395061\ttest: 0.1371647\tbest: 0.1371647 (5000)\ttotal: 59.4s\tremaining: 3h 16m 53s\n",
      "5500:\tlearn: 0.0371915\ttest: 0.1363752\tbest: 0.1363688 (5494)\ttotal: 1m 5s\tremaining: 3h 18m 24s\n",
      "6000:\tlearn: 0.0351641\ttest: 0.1357468\tbest: 0.1357468 (6000)\ttotal: 1m 12s\tremaining: 3h 18m 58s\n",
      "6500:\tlearn: 0.0333115\ttest: 0.1352032\tbest: 0.1352030 (6499)\ttotal: 1m 18s\tremaining: 3h 19m 13s\n",
      "7000:\tlearn: 0.0316795\ttest: 0.1348844\tbest: 0.1348844 (7000)\ttotal: 1m 24s\tremaining: 3h 19m 35s\n",
      "7500:\tlearn: 0.0301793\ttest: 0.1344742\tbest: 0.1344662 (7494)\ttotal: 1m 30s\tremaining: 3h 19m 57s\n",
      "8000:\tlearn: 0.0288098\ttest: 0.1340972\tbest: 0.1340972 (8000)\ttotal: 1m 36s\tremaining: 3h 19m 25s\n",
      "8500:\tlearn: 0.0275565\ttest: 0.1338914\tbest: 0.1338893 (8495)\ttotal: 1m 42s\tremaining: 3h 19m 43s\n",
      "9000:\tlearn: 0.0264037\ttest: 0.1336294\tbest: 0.1336269 (8996)\ttotal: 1m 48s\tremaining: 3h 18m 51s\n",
      "9500:\tlearn: 0.0253516\ttest: 0.1334721\tbest: 0.1334697 (9483)\ttotal: 1m 54s\tremaining: 3h 18m 35s\n",
      "10000:\tlearn: 0.0243527\ttest: 0.1332331\tbest: 0.1332291 (9997)\ttotal: 2m\tremaining: 3h 18m 23s\n",
      "10500:\tlearn: 0.0234104\ttest: 0.1330482\tbest: 0.1330482 (10500)\ttotal: 2m 6s\tremaining: 3h 18m 11s\n",
      "11000:\tlearn: 0.0225453\ttest: 0.1328681\tbest: 0.1328679 (10999)\ttotal: 2m 12s\tremaining: 3h 18m 44s\n",
      "bestTest = 0.132790747\n",
      "bestIteration = 11248\n",
      "Shrink model to first 11249 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 4 y_cox\n",
      "0:\tlearn: 0.8138848\ttest: 0.8149017\tbest: 0.8149017 (0)\ttotal: 11ms\tremaining: 3h 4m 5s\n",
      "500:\tlearn: 0.1205177\ttest: 0.1884855\tbest: 0.1884855 (500)\ttotal: 5.78s\tremaining: 3h 12m 5s\n",
      "1000:\tlearn: 0.0914147\ttest: 0.1683347\tbest: 0.1683347 (1000)\ttotal: 12.3s\tremaining: 3h 25m 2s\n",
      "1500:\tlearn: 0.0759944\ttest: 0.1598802\tbest: 0.1598680 (1498)\ttotal: 18.8s\tremaining: 3h 28m 37s\n",
      "2000:\tlearn: 0.0662235\ttest: 0.1551696\tbest: 0.1551557 (1999)\ttotal: 25.1s\tremaining: 3h 28m 58s\n",
      "2500:\tlearn: 0.0590660\ttest: 0.1517657\tbest: 0.1517594 (2499)\ttotal: 31.9s\tremaining: 3h 32m 3s\n",
      "3000:\tlearn: 0.0533858\ttest: 0.1495811\tbest: 0.1495786 (2997)\ttotal: 38.3s\tremaining: 3h 32m 16s\n",
      "3500:\tlearn: 0.0487840\ttest: 0.1479131\tbest: 0.1479097 (3498)\ttotal: 44.9s\tremaining: 3h 33m 8s\n",
      "4000:\tlearn: 0.0450960\ttest: 0.1465355\tbest: 0.1465236 (3995)\ttotal: 51.5s\tremaining: 3h 33m 41s\n",
      "4500:\tlearn: 0.0419873\ttest: 0.1457207\tbest: 0.1457192 (4499)\ttotal: 58.2s\tremaining: 3h 34m 21s\n",
      "5000:\tlearn: 0.0392609\ttest: 0.1450034\tbest: 0.1449932 (4995)\ttotal: 1m 4s\tremaining: 3h 34m 17s\n",
      "5500:\tlearn: 0.0369169\ttest: 0.1443576\tbest: 0.1443576 (5500)\ttotal: 1m 11s\tremaining: 3h 34m 38s\n",
      "6000:\tlearn: 0.0348295\ttest: 0.1437373\tbest: 0.1437232 (5993)\ttotal: 1m 17s\tremaining: 3h 34m 30s\n",
      "6500:\tlearn: 0.0329472\ttest: 0.1432847\tbest: 0.1432824 (6494)\ttotal: 1m 23s\tremaining: 3h 33m 49s\n",
      "7000:\tlearn: 0.0313153\ttest: 0.1428676\tbest: 0.1428675 (6999)\ttotal: 1m 29s\tremaining: 3h 31m 53s\n",
      "7500:\tlearn: 0.0297714\ttest: 0.1425153\tbest: 0.1425109 (7498)\ttotal: 1m 35s\tremaining: 3h 30m 48s\n",
      "8000:\tlearn: 0.0283819\ttest: 0.1423313\tbest: 0.1423290 (7979)\ttotal: 1m 41s\tremaining: 3h 30m 41s\n",
      "bestTest = 0.1421995202\n",
      "bestIteration = 8247\n",
      "Shrink model to first 8248 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 5 y_cox\n",
      "0:\tlearn: 0.8147265\ttest: 0.8039390\tbest: 0.8039390 (0)\ttotal: 15.2ms\tremaining: 4h 12m 44s\n",
      "500:\tlearn: 0.1208412\ttest: 0.1681170\tbest: 0.1681170 (500)\ttotal: 5.76s\tremaining: 3h 11m 24s\n",
      "1000:\tlearn: 0.0904996\ttest: 0.1484511\tbest: 0.1484511 (1000)\ttotal: 12s\tremaining: 3h 18m 48s\n",
      "1500:\tlearn: 0.0752356\ttest: 0.1392311\tbest: 0.1392311 (1500)\ttotal: 17.7s\tremaining: 3h 16m 6s\n",
      "2000:\tlearn: 0.0655212\ttest: 0.1344951\tbest: 0.1344830 (1999)\ttotal: 23.5s\tremaining: 3h 15m 1s\n",
      "2500:\tlearn: 0.0585700\ttest: 0.1315043\tbest: 0.1315043 (2500)\ttotal: 29.3s\tremaining: 3h 14m 54s\n",
      "3000:\tlearn: 0.0533550\ttest: 0.1293048\tbest: 0.1293022 (2999)\ttotal: 34.8s\tremaining: 3h 12m 51s\n",
      "3500:\tlearn: 0.0489422\ttest: 0.1277465\tbest: 0.1277377 (3486)\ttotal: 40.6s\tremaining: 3h 12m 39s\n",
      "4000:\tlearn: 0.0453728\ttest: 0.1265049\tbest: 0.1265049 (4000)\ttotal: 47.1s\tremaining: 3h 15m 36s\n",
      "4500:\tlearn: 0.0423680\ttest: 0.1254675\tbest: 0.1254667 (4498)\ttotal: 53.7s\tremaining: 3h 17m 52s\n",
      "5000:\tlearn: 0.0397080\ttest: 0.1247143\tbest: 0.1247134 (4999)\ttotal: 1m\tremaining: 3h 21m 4s\n",
      "5500:\tlearn: 0.0374074\ttest: 0.1242327\tbest: 0.1242327 (5500)\ttotal: 1m 7s\tremaining: 3h 23m 25s\n",
      "6000:\tlearn: 0.0353821\ttest: 0.1236751\tbest: 0.1236724 (5999)\ttotal: 1m 14s\tremaining: 3h 25m 26s\n",
      "6500:\tlearn: 0.0335095\ttest: 0.1233261\tbest: 0.1233256 (6492)\ttotal: 1m 20s\tremaining: 3h 24m 35s\n",
      "7000:\tlearn: 0.0318476\ttest: 0.1228835\tbest: 0.1228820 (6998)\ttotal: 1m 26s\tremaining: 3h 23m 54s\n",
      "7500:\tlearn: 0.0303582\ttest: 0.1225349\tbest: 0.1225248 (7490)\ttotal: 1m 32s\tremaining: 3h 23m 42s\n",
      "8000:\tlearn: 0.0290174\ttest: 0.1223341\tbest: 0.1223329 (7994)\ttotal: 1m 37s\tremaining: 3h 22m 14s\n",
      "8500:\tlearn: 0.0277093\ttest: 0.1221237\tbest: 0.1221237 (8500)\ttotal: 1m 43s\tremaining: 3h 21m 4s\n",
      "bestTest = 0.1220316996\n",
      "bestIteration = 8694\n",
      "Shrink model to first 8695 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 6 y_cox\n",
      "0:\tlearn: 0.8179008\ttest: 0.7774429\tbest: 0.7774429 (0)\ttotal: 9.86ms\tremaining: 2h 44m 16s\n",
      "500:\tlearn: 0.1215479\ttest: 0.1711856\tbest: 0.1711856 (500)\ttotal: 5.52s\tremaining: 3h 3m 34s\n",
      "1000:\tlearn: 0.0926087\ttest: 0.1535512\tbest: 0.1535447 (997)\ttotal: 11.9s\tremaining: 3h 17m 20s\n",
      "1500:\tlearn: 0.0773861\ttest: 0.1458119\tbest: 0.1458119 (1500)\ttotal: 17.7s\tremaining: 3h 16m 35s\n",
      "2000:\tlearn: 0.0674560\ttest: 0.1416579\tbest: 0.1416579 (2000)\ttotal: 23.5s\tremaining: 3h 15m 38s\n",
      "2500:\tlearn: 0.0604026\ttest: 0.1389852\tbest: 0.1389636 (2496)\ttotal: 29.3s\tremaining: 3h 15m 3s\n",
      "3000:\tlearn: 0.0547178\ttest: 0.1368699\tbest: 0.1368699 (3000)\ttotal: 35.5s\tremaining: 3h 16m 48s\n",
      "3500:\tlearn: 0.0503013\ttest: 0.1355455\tbest: 0.1355455 (3500)\ttotal: 41.8s\tremaining: 3h 18m 20s\n",
      "4000:\tlearn: 0.0466840\ttest: 0.1345070\tbest: 0.1345006 (3998)\ttotal: 48.3s\tremaining: 3h 20m 29s\n",
      "4500:\tlearn: 0.0434757\ttest: 0.1338342\tbest: 0.1338211 (4492)\ttotal: 54.9s\tremaining: 3h 22m 26s\n",
      "5000:\tlearn: 0.0407846\ttest: 0.1330733\tbest: 0.1330731 (4997)\ttotal: 1m 1s\tremaining: 3h 23m 58s\n",
      "5500:\tlearn: 0.0384428\ttest: 0.1325192\tbest: 0.1325169 (5481)\ttotal: 1m 7s\tremaining: 3h 24m 12s\n",
      "6000:\tlearn: 0.0363204\ttest: 0.1320969\tbest: 0.1320969 (6000)\ttotal: 1m 14s\tremaining: 3h 24m 39s\n",
      "6500:\tlearn: 0.0344508\ttest: 0.1316294\tbest: 0.1316153 (6485)\ttotal: 1m 19s\tremaining: 3h 23m 19s\n",
      "7000:\tlearn: 0.0328400\ttest: 0.1313910\tbest: 0.1313859 (6982)\ttotal: 1m 25s\tremaining: 3h 22m 43s\n",
      "7500:\tlearn: 0.0313801\ttest: 0.1311121\tbest: 0.1311109 (7499)\ttotal: 1m 31s\tremaining: 3h 22m 41s\n",
      "bestTest = 0.1310397295\n",
      "bestIteration = 7722\n",
      "Shrink model to first 7723 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 7 y_cox\n",
      "0:\tlearn: 0.8110130\ttest: 0.8445571\tbest: 0.8445571 (0)\ttotal: 10ms\tremaining: 2h 47m 8s\n",
      "500:\tlearn: 0.1244578\ttest: 0.1933710\tbest: 0.1933551 (499)\ttotal: 5.48s\tremaining: 3h 2m 8s\n",
      "1000:\tlearn: 0.0932025\ttest: 0.1716930\tbest: 0.1716930 (1000)\ttotal: 11.8s\tremaining: 3h 16m 32s\n",
      "1500:\tlearn: 0.0773472\ttest: 0.1617925\tbest: 0.1617925 (1500)\ttotal: 18.4s\tremaining: 3h 23m 42s\n",
      "2000:\tlearn: 0.0673853\ttest: 0.1567344\tbest: 0.1567181 (1999)\ttotal: 24.3s\tremaining: 3h 22m 7s\n",
      "2500:\tlearn: 0.0601273\ttest: 0.1535454\tbest: 0.1535420 (2499)\ttotal: 30.2s\tremaining: 3h 20m 45s\n",
      "3000:\tlearn: 0.0544348\ttest: 0.1511605\tbest: 0.1511605 (3000)\ttotal: 36.4s\tremaining: 3h 21m 31s\n",
      "3500:\tlearn: 0.0499777\ttest: 0.1493967\tbest: 0.1493967 (3500)\ttotal: 42.4s\tremaining: 3h 21m 5s\n",
      "4000:\tlearn: 0.0463390\ttest: 0.1480307\tbest: 0.1480307 (4000)\ttotal: 48.5s\tremaining: 3h 21m 21s\n",
      "4500:\tlearn: 0.0432578\ttest: 0.1469817\tbest: 0.1469716 (4497)\ttotal: 54.7s\tremaining: 3h 21m 30s\n",
      "5000:\tlearn: 0.0405430\ttest: 0.1462228\tbest: 0.1462228 (5000)\ttotal: 1m\tremaining: 3h 21m 24s\n",
      "5500:\tlearn: 0.0381770\ttest: 0.1454513\tbest: 0.1454231 (5489)\ttotal: 1m 6s\tremaining: 3h 21m 32s\n",
      "bestTest = 0.1451775338\n",
      "bestIteration = 5698\n",
      "Shrink model to first 5699 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 8 y_cox\n",
      "0:\tlearn: 0.8129378\ttest: 0.8262256\tbest: 0.8262256 (0)\ttotal: 10.1ms\tremaining: 2h 49m 6s\n",
      "500:\tlearn: 0.1223283\ttest: 0.1837890\tbest: 0.1837686 (499)\ttotal: 5.56s\tremaining: 3h 4m 53s\n",
      "1000:\tlearn: 0.0918989\ttest: 0.1649103\tbest: 0.1649103 (1000)\ttotal: 11.7s\tremaining: 3h 15m 25s\n",
      "1500:\tlearn: 0.0768657\ttest: 0.1561765\tbest: 0.1561765 (1500)\ttotal: 17.6s\tremaining: 3h 15m 19s\n",
      "2000:\tlearn: 0.0669182\ttest: 0.1512386\tbest: 0.1512386 (2000)\ttotal: 23.6s\tremaining: 3h 16m 2s\n",
      "2500:\tlearn: 0.0597208\ttest: 0.1477770\tbest: 0.1477770 (2500)\ttotal: 29.5s\tremaining: 3h 15m 52s\n",
      "3000:\tlearn: 0.0541712\ttest: 0.1457115\tbest: 0.1457115 (3000)\ttotal: 35.8s\tremaining: 3h 18m 17s\n",
      "3500:\tlearn: 0.0498482\ttest: 0.1440891\tbest: 0.1440891 (3500)\ttotal: 41.9s\tremaining: 3h 18m 57s\n",
      "4000:\tlearn: 0.0461791\ttest: 0.1427799\tbest: 0.1427790 (3998)\ttotal: 48.2s\tremaining: 3h 20m\n",
      "4500:\tlearn: 0.0431006\ttest: 0.1416475\tbest: 0.1416433 (4499)\ttotal: 54.4s\tremaining: 3h 20m 42s\n",
      "5000:\tlearn: 0.0404180\ttest: 0.1408723\tbest: 0.1408723 (5000)\ttotal: 1m\tremaining: 3h 22m 14s\n",
      "5500:\tlearn: 0.0380526\ttest: 0.1402641\tbest: 0.1402641 (5500)\ttotal: 1m 6s\tremaining: 3h 21m 43s\n",
      "6000:\tlearn: 0.0359827\ttest: 0.1398199\tbest: 0.1398199 (6000)\ttotal: 1m 13s\tremaining: 3h 21m 53s\n",
      "6500:\tlearn: 0.0341411\ttest: 0.1394357\tbest: 0.1394353 (6499)\ttotal: 1m 19s\tremaining: 3h 22m 25s\n",
      "7000:\tlearn: 0.0324620\ttest: 0.1390465\tbest: 0.1390372 (6961)\ttotal: 1m 25s\tremaining: 3h 22m 16s\n",
      "7500:\tlearn: 0.0309378\ttest: 0.1387522\tbest: 0.1387433 (7494)\ttotal: 1m 31s\tremaining: 3h 22m 21s\n",
      "8000:\tlearn: 0.0295561\ttest: 0.1385061\tbest: 0.1385044 (7996)\ttotal: 1m 38s\tremaining: 3h 22m 46s\n",
      "8500:\tlearn: 0.0282373\ttest: 0.1381883\tbest: 0.1381868 (8499)\ttotal: 1m 44s\tremaining: 3h 22m 46s\n",
      "9000:\tlearn: 0.0270987\ttest: 0.1379802\tbest: 0.1379758 (8999)\ttotal: 1m 50s\tremaining: 3h 22m 33s\n",
      "9500:\tlearn: 0.0260301\ttest: 0.1378255\tbest: 0.1378134 (9448)\ttotal: 1m 56s\tremaining: 3h 22m 29s\n",
      "10000:\tlearn: 0.0250385\ttest: 0.1376975\tbest: 0.1376967 (9997)\ttotal: 2m 2s\tremaining: 3h 22m 44s\n",
      "10500:\tlearn: 0.0241110\ttest: 0.1375795\tbest: 0.1375636 (10476)\ttotal: 2m 9s\tremaining: 3h 23m 1s\n",
      "bestTest = 0.1374723368\n",
      "bestIteration = 10704\n",
      "Shrink model to first 10705 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 9 y_cox\n",
      "0:\tlearn: 0.8118256\ttest: 0.8339269\tbest: 0.8339269 (0)\ttotal: 14.1ms\tremaining: 3h 55m 22s\n",
      "500:\tlearn: 0.1235853\ttest: 0.1824470\tbest: 0.1824470 (500)\ttotal: 5.84s\tremaining: 3h 14m 20s\n",
      "1000:\tlearn: 0.0937238\ttest: 0.1613954\tbest: 0.1613954 (1000)\ttotal: 12.1s\tremaining: 3h 21m 56s\n",
      "1500:\tlearn: 0.0786342\ttest: 0.1518240\tbest: 0.1518158 (1498)\ttotal: 18.1s\tremaining: 3h 21m 11s\n",
      "2000:\tlearn: 0.0689047\ttest: 0.1460884\tbest: 0.1460882 (1999)\ttotal: 24.5s\tremaining: 3h 23m 51s\n",
      "2500:\tlearn: 0.0616827\ttest: 0.1425158\tbest: 0.1425158 (2500)\ttotal: 30.6s\tremaining: 3h 23m 19s\n",
      "3000:\tlearn: 0.0561139\ttest: 0.1400666\tbest: 0.1400666 (3000)\ttotal: 36.6s\tremaining: 3h 22m 23s\n",
      "3500:\tlearn: 0.0515792\ttest: 0.1382377\tbest: 0.1382331 (3495)\ttotal: 42.5s\tremaining: 3h 21m 41s\n",
      "4000:\tlearn: 0.0479702\ttest: 0.1369646\tbest: 0.1369646 (4000)\ttotal: 48.6s\tremaining: 3h 21m 45s\n",
      "4500:\tlearn: 0.0447848\ttest: 0.1358415\tbest: 0.1358415 (4500)\ttotal: 54.7s\tremaining: 3h 21m 44s\n",
      "5000:\tlearn: 0.0420388\ttest: 0.1348446\tbest: 0.1348446 (4997)\ttotal: 1m\tremaining: 3h 20m 21s\n",
      "5500:\tlearn: 0.0396828\ttest: 0.1341773\tbest: 0.1341738 (5494)\ttotal: 1m 5s\tremaining: 3h 18m 17s\n",
      "6000:\tlearn: 0.0376635\ttest: 0.1336227\tbest: 0.1336227 (6000)\ttotal: 1m 11s\tremaining: 3h 17m 45s\n",
      "6500:\tlearn: 0.0358352\ttest: 0.1332203\tbest: 0.1332203 (6500)\ttotal: 1m 17s\tremaining: 3h 17m 51s\n",
      "7000:\tlearn: 0.0341919\ttest: 0.1328438\tbest: 0.1328392 (6997)\ttotal: 1m 23s\tremaining: 3h 17m 47s\n",
      "7500:\tlearn: 0.0326805\ttest: 0.1325885\tbest: 0.1325862 (7416)\ttotal: 1m 30s\tremaining: 3h 18m 36s\n",
      "bestTest = 0.1325861679\n",
      "bestIteration = 7416\n",
      "Shrink model to first 7417 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 10 y_cox\n",
      "0:\tlearn: 0.8139459\ttest: 0.8186713\tbest: 0.8186713 (0)\ttotal: 10.3ms\tremaining: 2h 51m 19s\n",
      "500:\tlearn: 0.1228523\ttest: 0.1704611\tbest: 0.1704611 (500)\ttotal: 5.58s\tremaining: 3h 5m 30s\n",
      "1000:\tlearn: 0.0923192\ttest: 0.1525178\tbest: 0.1525178 (1000)\ttotal: 11.9s\tremaining: 3h 17m 34s\n",
      "1500:\tlearn: 0.0769890\ttest: 0.1447642\tbest: 0.1447642 (1500)\ttotal: 18.2s\tremaining: 3h 21m 14s\n",
      "2000:\tlearn: 0.0667910\ttest: 0.1402835\tbest: 0.1402835 (2000)\ttotal: 24.2s\tremaining: 3h 21m 14s\n",
      "2500:\tlearn: 0.0594479\ttest: 0.1372350\tbest: 0.1372350 (2500)\ttotal: 30.4s\tremaining: 3h 21m 48s\n",
      "3000:\tlearn: 0.0539552\ttest: 0.1354626\tbest: 0.1354611 (2988)\ttotal: 36.2s\tremaining: 3h 20m 37s\n",
      "3500:\tlearn: 0.0496050\ttest: 0.1340227\tbest: 0.1340039 (3485)\ttotal: 42.4s\tremaining: 3h 21m 20s\n",
      "4000:\tlearn: 0.0460173\ttest: 0.1330188\tbest: 0.1330124 (3998)\ttotal: 48.8s\tremaining: 3h 22m 38s\n",
      "4500:\tlearn: 0.0428834\ttest: 0.1319745\tbest: 0.1319720 (4497)\ttotal: 55.1s\tremaining: 3h 23m 8s\n",
      "5000:\tlearn: 0.0402826\ttest: 0.1313643\tbest: 0.1313607 (4999)\ttotal: 1m 1s\tremaining: 3h 22m 37s\n",
      "5500:\tlearn: 0.0380035\ttest: 0.1308479\tbest: 0.1308401 (5494)\ttotal: 1m 6s\tremaining: 3h 21m 15s\n",
      "6000:\tlearn: 0.0359172\ttest: 0.1303925\tbest: 0.1303913 (5999)\ttotal: 1m 12s\tremaining: 3h 20m 9s\n",
      "6500:\tlearn: 0.0340737\ttest: 0.1301008\tbest: 0.1300917 (6474)\ttotal: 1m 17s\tremaining: 3h 17m 37s\n",
      "7000:\tlearn: 0.0324195\ttest: 0.1297841\tbest: 0.1297755 (6968)\ttotal: 1m 23s\tremaining: 3h 16m 25s\n",
      "7500:\tlearn: 0.0309551\ttest: 0.1295388\tbest: 0.1295189 (7477)\ttotal: 1m 28s\tremaining: 3h 15m 44s\n",
      "bestTest = 0.129306201\n",
      "bestIteration = 7884\n",
      "Shrink model to first 7885 iterations.\n",
      "==================================================\n",
      "catboost our out of folds CV score is 0.6596850501957573\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Training\n",
    "# ====================================================\n",
    "# for method in CFG.METHOD_LIST:\n",
    "#     gradient_boosting_model_cv_training(method, train, CFG.target_col_list, FEATURES, CATS)\n",
    "\n",
    "# # Cox models\n",
    "# for method in [\"xgboost_cox\", \"catboost_cox\"]:\n",
    "#     gradient_boosting_model_cv_training(method, train, CFG.cox_target_col_list, FEATURES, CATS)\n",
    "# Non-Cox models\n",
    "for method in [\"lightgbm\", \"xgboost\", \"catboost\"]:\n",
    "    gradient_boosting_model_cv_training(method, train, CFG.target_col_list, FEATURES, CATS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Inference functions\n",
    "# ====================================================\n",
    "def lightgbm_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"lightgbm_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def xgboost_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"xgboost_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        # pred = model.predict(xgb.DMatrix(x_test, enable_categorical=True))\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def catboost_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"catboost_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "# Cox models\n",
    "def xgboost_cox_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"xgboost_cox_efs_time2_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def catboost_cox_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"catboost_cox_efs_time2_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list, target_col: str):\n",
    "    x_test = test_df[features]\n",
    "    if method == \"lightgbm\":\n",
    "        test_pred = lightgbm_inference(x_test, target_col)\n",
    "    if method == \"xgboost\":\n",
    "        test_pred = xgboost_inference(x_test, target_col)\n",
    "    if method == \"catboost\":\n",
    "        test_pred = catboost_inference(x_test, target_col)\n",
    "    # Cox models\n",
    "    elif method == \"xgboost_cox\":\n",
    "        test_pred = xgboost_cox_inference(x_test, target_col)\n",
    "    elif method == \"catboost_cox\":\n",
    "        test_pred = catboost_cox_inference(x_test, target_col)\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "def predicting(input_df: pd.DataFrame, features: list):\n",
    "    output_df = input_df.copy()\n",
    "    for target_col in CFG.target_col_list:\n",
    "        # output_df[target_col] = 0\n",
    "        for method in CFG.METHOD_LIST:\n",
    "            output_df[f\"{method}_pred_{target_col}\"] = gradient_boosting_model_inference(\n",
    "                method, input_df, features, target_col\n",
    "            )\n",
    "            # output_df[target_col] += CFG.model_weight_dict[method] * output_df[f\"{method}_pred_{target_col}\"]\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28801</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28802</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  prediction\n",
       "0  28800         6.0\n",
       "1  28801         9.0\n",
       "2  28802         3.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Inference\n",
    "# ====================================================\n",
    "output_df = predicting(test, FEATURES)\n",
    "pred_lgb = output_df[\"lightgbm_pred_y_cox\"]\n",
    "pred_xgb = output_df[\"xgboost_pred_y_cox\"]\n",
    "pred_cat = output_df[\"catboost_pred_y_cox\"]\n",
    "\n",
    "\n",
    "submission = pd.read_csv(CFG.DATA_PATH / \"sample_submission.csv\")\n",
    "submission[\"prediction\"] = (\n",
    "    rankdata(pred_lgb) + rankdata(pred_xgb) + rankdata(pred_cat)\n",
    ")\n",
    "submission.to_csv(CFG.OUTPUT_DIR / \"submission.csv\", index=False)\n",
    "print(\"Sub shape:\", submission.shape)\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import config  # edit config.py as needed\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import scipy as sp\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter, NelsonAalenFitter\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from metric import score  # edit metric.py as needed\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import rankdata\n",
    "from seed import seed_everything  # edit seed.py as needed\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    DRY_RUN = False\n",
    "    EXP_NAME = config.EXP_NAME\n",
    "    AUTHOR = \"marumarukun\"\n",
    "    COMPETITION = config.KAGGLE_COMPETITION_NAME\n",
    "    DATA_PATH = config.COMP_DATASET_DIR\n",
    "    OUTPUT_DIR = config.OUTPUT_DIR\n",
    "    MODEL_PATH = config.OUTPUT_DIR / \"models\"  # モデル作成・実験時はこちらを使用\n",
    "    # MODEL_PATH = config.ARTIFACT_EXP_DIR(config.EXP_NAME) / \"models\"  # 提出時はこちらを使用\n",
    "    METHOD_LIST = [\"lightgbm\", \"xgboost\", \"catboost\"]\n",
    "    SEED = 42\n",
    "    n_folds = 2 if DRY_RUN else 10\n",
    "    target_col_list = [\"y_cox\"]\n",
    "    # cox_target_col_list = [\"efs_time2\"]\n",
    "    # group_col = \"race_group\"  # Required for GroupKFold (edit as needed)\n",
    "    stratified_col = \"race_group_efs\"  # Required for StratifiedKFold (edit as needed)\n",
    "    num_boost_round = 100 if DRY_RUN else 1000000\n",
    "    early_stopping_round = 10 if DRY_RUN else 500  # 10÷lrで設定\n",
    "    verbose = 500\n",
    "\n",
    "    # https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "    # https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "    # https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\n",
    "    regression_lgb_params = {\n",
    "        \"objective\": \"regression\",\n",
    "        # \"metric\": \"mae\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"max_depth\": 5,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"subsample_freq\": 1,\n",
    "        \"seed\": SEED,\n",
    "        \"device\": \"cuda\",  # cpu/gpu/cuda\n",
    "    }\n",
    "    # https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "    # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
    "    # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
    "    regression_xgb_params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        # \"eval_metric\": \"mae\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"max_depth\": 5,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": SEED,\n",
    "        \"device\": \"cuda\",  # cpu/gpu/cuda\n",
    "    }\n",
    "    # https://catboost.ai/docs/en/references/training-parameters/\n",
    "    # https://catboost.ai/docs/en/concepts/python-reference_catboostregressor\n",
    "    # https://catboost.ai/docs/en/concepts/python-reference_catboostclassifier\n",
    "    regression_cat_params = {\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"iterations\": num_boost_round,\n",
    "        # \"depth\": 5,\n",
    "        \"grow_policy\": \"Lossguide\",\n",
    "        \"random_seed\": SEED,\n",
    "        \"task_type\": \"GPU\",  # CPU/GPU\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "seed_everything(CFG.SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "train = pl.read_csv(CFG.DATA_PATH / \"train.csv\", try_parse_dates=True)\n",
    "test = pl.read_csv(CFG.DATA_PATH / \"test.csv\", try_parse_dates=True)\n",
    "# make index column\n",
    "# train = train.with_row_index()\n",
    "# test = test.with_row_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Make fold column\n",
    "# ====================================================\n",
    "# race_group_efs列を作成\n",
    "train = train.with_columns((pl.col(\"race_group\").cast(str) + \"_\" + pl.col(\"efs\").cast(str)).alias(\"race_group_efs\"))\n",
    "\n",
    "fold_array = np.zeros(train.height)\n",
    "skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.SEED)\n",
    "for fold, (_, val_idx) in enumerate(skf.split(train, train[CFG.stratified_col]), start=1):\n",
    "    fold_array[val_idx] = fold\n",
    "train = train.with_columns(pl.Series(fold_array, dtype=pl.Int8).alias(\"fold\"))\n",
    "\n",
    "# fold_array = np.zeros(train.height)\n",
    "# kf = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.SEED)\n",
    "# for fold, (_, val_idx) in enumerate(kf.split(train), start=1):\n",
    "#     fold_array[val_idx] = fold\n",
    "# train = train.with_columns(pl.Series(fold_array, dtype=pl.Int8).alias(\"fold\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.to_pandas()\n",
    "test = test.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'hla_match_c_high', 'hla_high_res_8', 'tbi_status', 'arrhythmia', 'hla_low_res_6', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'hla_high_res_6', 'cmv_status', 'hla_high_res_10', 'hla_match_dqb1_high', 'tce_imm_match', 'hla_nmdp_6', 'hla_match_c_low', 'rituximab', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'year_hct', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hla_match_a_high', 'hepatic_severe', 'donor_age', 'prior_tumor', 'hla_match_b_low', 'peptic_ulcer', 'age_at_hct', 'hla_match_a_low', 'gvhd_proph', 'rheum_issue', 'sex_match', 'hla_match_b_high', 'race_group', 'comorbidity_score', 'karnofsky_score', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'hla_low_res_8', 'cardiac', 'hla_match_drb1_high', 'pulm_moderate', 'hla_low_res_10']\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Set categorical columns etc. (pandas operation from here)\n",
    "# ====================================================\n",
    "RMV = [\"ID\", \"efs\", \"efs_time\", \"y_kaplan\", \"y_nelson\", \"fold\", \"race_group_efs\"]\n",
    "FEATURES = [c for c in train.columns if c not in RMV]\n",
    "print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In these features, there are 35 CATEGORICAL FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status', 'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe', 'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match', 'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'cardiac', 'pulm_moderate']\n"
     ]
    }
   ],
   "source": [
    "CATS = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype == \"object\":\n",
    "        CATS.append(c)\n",
    "        train[c] = train[c].fillna(\"NAN\")\n",
    "        test[c] = test[c].fillna(\"NAN\")\n",
    "print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We LABEL ENCODE the CATEGORICAL FEATURES: dri_score, psych_disturb, cyto_score, diabetes, tbi_status, arrhythmia, graft_type, vent_hist, renal_issue, pulm_severe, prim_disease_hct, cmv_status, tce_imm_match, rituximab, prod_type, cyto_score_detail, conditioning_intensity, ethnicity, obesity, mrd_hct, in_vivo_tcd, tce_match, hepatic_severe, prior_tumor, peptic_ulcer, gvhd_proph, rheum_issue, sex_match, race_group, hepatic_mild, tce_div_match, donor_related, melphalan_dose, cardiac, pulm_moderate, "
     ]
    }
   ],
   "source": [
    "combined = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "# print(\"Combined data shape:\", combined.shape )\n",
    "\n",
    "# LABEL ENCODE CATEGORICAL FEATURES\n",
    "print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \", end=\"\")\n",
    "for c in FEATURES:\n",
    "    # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "    if c in CATS:\n",
    "        print(f\"{c}, \", end=\"\")\n",
    "        combined[c], _ = combined[c].factorize()\n",
    "        combined[c] -= combined[c].min()\n",
    "        combined[c] = combined[c].astype(\"int32\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "\n",
    "    # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "    else:\n",
    "        if combined[c].dtype == \"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype == \"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "\n",
    "train = combined.iloc[: len(train)].copy()\n",
    "test = combined.iloc[len(train) :].reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CoxPHFitter\n",
    "# ====================================================\n",
    "\n",
    "data = train.copy().drop([\"ID\", \"fold\", \"race_group_efs\"], axis=1)\n",
    "\n",
    "# 数値列の欠損を-1で埋める\n",
    "for c in data.columns:\n",
    "    if c not in CATS:\n",
    "        data[c] = data[c].fillna(-1)\n",
    "\n",
    "# カテゴリカル変数のダミー変数化\n",
    "data = pd.get_dummies(data, columns=CATS, drop_first=True)\n",
    "\n",
    "# Drop constant columns if they exist\n",
    "data = data.loc[:, data.nunique() > 1]\n",
    "\n",
    "cph = CoxPHFitter(penalizer=0.01)\n",
    "cph.fit(data, duration_col=\"efs_time\", event_col=\"efs\")\n",
    "\n",
    "train[\"y_cox\"] = cph.predict_partial_hazard(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score of target created by CoxPHFitter = 0.6611743782604956\n"
     ]
    }
   ],
   "source": [
    "y_true = train[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
    "y_target = train[[\"ID\"]].copy()\n",
    "y_target[\"prediction\"] = train[\"y_cox\"]\n",
    "m = score(y_true.copy(), y_target.copy(), \"ID\")\n",
    "print(\"\\nScore of target created by CoxPHFitter =\", m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Training functions\n",
    "# ====================================================\n",
    "def lightgbm_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    model = LGBMRegressor(\n",
    "        **CFG.regression_lgb_params,\n",
    "        n_estimators=CFG.num_boost_round,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        categorical_feature=categorical_features,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=CFG.early_stopping_round),\n",
    "            lgb.log_evaluation(CFG.verbose),\n",
    "        ],\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def xgboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "):\n",
    "    model = XGBRegressor(\n",
    "        **CFG.regression_xgb_params,\n",
    "        n_estimators=CFG.num_boost_round,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=CFG.verbose,\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def catboost_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostRegressor(**CFG.regression_cat_params)\n",
    "    model.fit(\n",
    "        cat_train,\n",
    "        eval_set=[cat_valid],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose=CFG.verbose,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "# Cox models\n",
    "def xgboost_cox_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "):\n",
    "    model = XGBRegressor(\n",
    "        **CFG.regression_xgb_cox_params,\n",
    "        n_estimators=CFG.num_boost_round,\n",
    "    )\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=CFG.verbose,\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def catboost_cox_training(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    x_valid: pd.DataFrame,\n",
    "    y_valid: pd.DataFrame,\n",
    "    categorical_features: list,\n",
    "):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostRegressor(**CFG.regression_cat_cox_params)\n",
    "    model.fit(\n",
    "        cat_train,\n",
    "        eval_set=[cat_valid],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose=CFG.verbose,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def gradient_boosting_model_cv_training(\n",
    "    method: str, train_df: pd.DataFrame, target_col_list: list, features: list, categorical_features: list\n",
    "):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    for target_col in target_col_list:\n",
    "        oof_predictions = np.zeros(len(train_df))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"{method} training fold {fold+1} {target_col}\")\n",
    "            x_train = train_df[train_df[\"fold\"] != fold + 1][features]\n",
    "            y_train = train_df[train_df[\"fold\"] != fold + 1][target_col]\n",
    "            x_valid = train_df[train_df[\"fold\"] == fold + 1][features]\n",
    "            y_valid = train_df[train_df[\"fold\"] == fold + 1][target_col]\n",
    "            if method == \"lightgbm\":\n",
    "                model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            elif method == \"xgboost\":\n",
    "                model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid)\n",
    "            elif method == \"catboost\":\n",
    "                model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            # Cox models\n",
    "            elif method == \"xgboost_cox\":\n",
    "                model, valid_pred = xgboost_cox_training(x_train, y_train, x_valid, y_valid)\n",
    "            elif method == \"catboost_cox\":\n",
    "                model, valid_pred = catboost_cox_training(x_train, y_train, x_valid, y_valid, categorical_features)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "            # Save best model\n",
    "            save_model_path = (\n",
    "                CFG.MODEL_PATH / f\"{method}_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\"\n",
    "            )\n",
    "            save_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            pickle.dump(\n",
    "                model,\n",
    "                open(\n",
    "                    save_model_path,\n",
    "                    \"wb\",\n",
    "                ),\n",
    "            )\n",
    "            # Add to out of folds array\n",
    "            oof_predictions[train_df[\"fold\"] == fold + 1] = valid_pred\n",
    "            del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "            gc.collect()\n",
    "\n",
    "        # Create a dataframe to store out of folds predictions\n",
    "        oof_predictions_df = pd.DataFrame()\n",
    "        oof_predictions_df[\"ID\"] = train_df[\"ID\"].values\n",
    "        oof_predictions_df[\"prediction\"] = oof_predictions\n",
    "        oof_predictions_df.to_csv(\n",
    "            CFG.OUTPUT_DIR / f\"oof_{method}_{target_col}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.csv\", index=False\n",
    "        )\n",
    "\n",
    "        # Compute out of folds metric\n",
    "        y_true = train_df[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy()\n",
    "        m = score(y_true.copy(), oof_predictions_df.copy(), \"ID\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"{method} our out of folds CV score is {m}\")\n",
    "        print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 1 y_cox\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 25920, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 1.252319\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's l2: 0.0552781\n",
      "[1000]\tvalid_0's l2: 0.032401\n",
      "[1500]\tvalid_0's l2: 0.0259233\n",
      "[2000]\tvalid_0's l2: 0.0229976\n",
      "[2500]\tvalid_0's l2: 0.0214667\n",
      "[3000]\tvalid_0's l2: 0.0204999\n",
      "[3500]\tvalid_0's l2: 0.0197787\n",
      "[4000]\tvalid_0's l2: 0.0192604\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Training\n",
    "# ====================================================\n",
    "# for method in CFG.METHOD_LIST:\n",
    "#     gradient_boosting_model_cv_training(method, train, CFG.target_col_list, FEATURES, CATS)\n",
    "\n",
    "# # Cox models\n",
    "# for method in [\"xgboost_cox\", \"catboost_cox\"]:\n",
    "#     gradient_boosting_model_cv_training(method, train, CFG.cox_target_col_list, FEATURES, CATS)\n",
    "# Non-Cox models\n",
    "for method in [\"lightgbm\", \"xgboost\", \"catboost\"]:\n",
    "    gradient_boosting_model_cv_training(method, train, CFG.target_col_list, FEATURES, CATS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Inference functions\n",
    "# ====================================================\n",
    "def lightgbm_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"lightgbm_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def xgboost_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"xgboost_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        # pred = model.predict(xgb.DMatrix(x_test, enable_categorical=True))\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def catboost_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"catboost_{target_col}_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "# Cox models\n",
    "def xgboost_cox_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"xgboost_cox_efs_time2_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def catboost_cox_inference(x_test: pd.DataFrame, target_col: str):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                CFG.MODEL_PATH / f\"catboost_cox_efs_time2_fold{fold + 1}_seed{CFG.SEED}_ver{CFG.EXP_NAME}.pkl\",\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "\n",
    "def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list, target_col: str):\n",
    "    x_test = test_df[features]\n",
    "    if method == \"lightgbm\":\n",
    "        test_pred = lightgbm_inference(x_test, target_col)\n",
    "    if method == \"xgboost\":\n",
    "        test_pred = xgboost_inference(x_test, target_col)\n",
    "    if method == \"catboost\":\n",
    "        test_pred = catboost_inference(x_test, target_col)\n",
    "    # Cox models\n",
    "    elif method == \"xgboost_cox\":\n",
    "        test_pred = xgboost_cox_inference(x_test, target_col)\n",
    "    elif method == \"catboost_cox\":\n",
    "        test_pred = catboost_cox_inference(x_test, target_col)\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "def predicting(input_df: pd.DataFrame, features: list):\n",
    "    output_df = input_df.copy()\n",
    "    for target_col in CFG.target_col_list:\n",
    "        # output_df[target_col] = 0\n",
    "        for method in CFG.METHOD_LIST:\n",
    "            output_df[f\"{method}_pred_{target_col}\"] = gradient_boosting_model_inference(\n",
    "                method, input_df, features, target_col\n",
    "            )\n",
    "            # output_df[target_col] += CFG.model_weight_dict[method] * output_df[f\"{method}_pred_{target_col}\"]\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28801</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28802</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  prediction\n",
       "0  28800        10.0\n",
       "1  28801        15.0\n",
       "2  28802         5.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # ====================================================\n",
    "# # Inference\n",
    "# # ====================================================\n",
    "# output_df = predicting(test, FEATURES)\n",
    "# pred_lgb = output_df[\"lightgbm_pred_y\"]\n",
    "# pred_xgb = output_df[\"xgboost_pred_y\"]\n",
    "# pred_cat = output_df[\"catboost_pred_y\"]\n",
    "# # Cox models\n",
    "# pred_cox_xgb = output_df[\"xgboost_cox_pred_y\"]\n",
    "# pred_cox_cat = output_df[\"catboost_cox_pred_y\"]\n",
    "\n",
    "# submission = pd.read_csv(CFG.DATA_PATH / \"sample_submission.csv\")\n",
    "# submission[\"prediction\"] = (\n",
    "#     rankdata(pred_lgb) + rankdata(pred_xgb) + rankdata(pred_cat) + rankdata(pred_cox_xgb) + rankdata(pred_cox_cat)\n",
    "# )\n",
    "# submission.to_csv(CFG.OUTPUT_DIR / \"submission.csv\", index=False)\n",
    "# print(\"Sub shape:\", submission.shape)\n",
    "# submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
